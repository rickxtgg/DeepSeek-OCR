#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeek-OCR T4 GPU è‡ªåŠ¨ä¿®å¤è„šæœ¬
================================

åŠŸèƒ½ï¼šè‡ªåŠ¨ä¿®å¤DeepSeek-OCRé¡¹ç›®ä¸­çš„T4 GPUå…¼å®¹æ€§é—®é¢˜å’ŒvLLMç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜

ä¿®å¤å†…å®¹ï¼š
1. T4 GPUå…¼å®¹æ€§ä¿®å¤:
   - æ·»åŠ  dtype='half' å‚æ•°ï¼ˆæ›¿æ¢bfloat16ä¸ºfloat16ï¼‰
   - ä¿®æ”¹ block_size ä»256åˆ°16
   - ä¿®å¤è§†è§‰ç¼–ç å™¨çš„dtypeè½¬æ¢
   - ä¿®å¤è¾“å…¥æ•°æ®çš„dtypeè½¬æ¢

2. vLLMç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤:
   - SamplingMetadata å¯¼å…¥å…¼å®¹
   - set_default_torch_dtype å¯¼å…¥å…¼å®¹
   - merge_multimodal_embeddings å¯¼å…¥å…¼å®¹
   - ModelRegistry å¯¼å…¥å…¼å®¹
   - AsyncLLMEngine/AsyncEngineArgs å¯¼å…¥å…¼å®¹

ä½¿ç”¨æ–¹æ³•ï¼š
    python auto_fix_t4_compatibility.py [é¡¹ç›®è·¯å¾„]
    
    å¦‚æœä¸æŒ‡å®šè·¯å¾„ï¼Œé»˜è®¤å¤„ç†å½“å‰ç›®å½•ä¸‹çš„ DeepSeek-OCR-master æ–‡ä»¶å¤¹

ç¤ºä¾‹ï¼š
    python auto_fix_t4_compatibility.py
    python auto_fix_t4_compatibility.py /path/to/DeepSeek-OCR

ä½œè€…ï¼šDeepSeek AI & Contributors
æ—¥æœŸï¼š2025-10-21
ç‰ˆæœ¬ï¼šv3.0
"""

import os
import sys
import shutil
import re
from pathlib import Path
from datetime import datetime


class Colors:
    """ç»ˆç«¯é¢œè‰²ä»£ç """
    RED = '\033[31m'
    GREEN = '\033[32m'
    YELLOW = '\033[33m'
    BLUE = '\033[34m'
    MAGENTA = '\033[35m'
    CYAN = '\033[36m'
    RESET = '\033[0m'
    BOLD = '\033[1m'


class T4CompatibilityFixer:
    """
    T4 GPU å…¼å®¹æ€§ä¿®å¤å™¨
    
    åŠŸèƒ½æè¿°ï¼š
        æä¾›å®Œæ•´çš„T4 GPUå…¼å®¹æ€§ä¿®å¤åŠŸèƒ½å’ŒvLLMç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤
        è‡ªåŠ¨æ£€æµ‹ã€å¤‡ä»½ã€ä¿®å¤å’ŒéªŒè¯æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶
    
    ä¸»è¦åŠŸèƒ½ï¼š
        - ç¯å¢ƒæ£€æŸ¥å’Œæ–‡ä»¶éªŒè¯
        - è‡ªåŠ¨å¤‡ä»½åŸå§‹æ–‡ä»¶
        - åº”ç”¨T4 GPUå…¼å®¹æ€§ä¿®å¤
        - åº”ç”¨vLLMç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤
        - ä¿®å¤ç»“æœéªŒè¯
        - æ¢å¤å¤‡ä»½åŠŸèƒ½
        - ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    
    ä¿®å¤å†…å®¹ï¼š
        T4 GPUä¿®å¤:
        1. dtype='half': åœ¨å¼•æ“å‚æ•°ä¸­æ·»åŠ float16æ”¯æŒ
        2. block_size: ä»256æ”¹ä¸º16
        3. è§†è§‰ç¼–ç å™¨: è½¬æ¢åˆ°float16
        4. è¾“å…¥æ•°æ®: åŠ¨æ€dtypeè½¬æ¢
        
        vLLMç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤:
        1. SamplingMetadata å¯¼å…¥å…¼å®¹
        2. set_default_torch_dtype å¯¼å…¥å…¼å®¹
        3. merge_multimodal_embeddings å¯¼å…¥å…¼å®¹
        4. ModelRegistry å¯¼å…¥å…¼å®¹
        5. AsyncLLMEngine/AsyncEngineArgs å¯¼å…¥å…¼å®¹
    
    ä½¿ç”¨æ–¹æ³•ï¼š
        fixer = T4CompatibilityFixer()
        fixer.run_interactive()
    """
    
    def __init__(self, project_path=None):
        """
        åˆå§‹åŒ–ä¿®å¤å™¨
        
        å‚æ•°ï¼š
            project_path (str, å¯é€‰): é¡¹ç›®è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„ DeepSeek-OCR-master
        """
        if project_path is None:
            project_path = os.path.join(os.getcwd(), 'DeepSeek-OCR-master')
        
        self.project_path = Path(project_path)
        self.vllm_path = self.project_path / 'DeepSeek-OCR-vllm'
        self.backup_dir = self.project_path / f'backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
        
        # éœ€è¦ä¿®å¤çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆOCRè„šæœ¬å’Œæ ¸å¿ƒæ¨¡å‹ï¼‰
        self.files_to_fix = [
            'run_dpsk_ocr_image.py',
            'run_dpsk_ocr_pdf.py',
            'run_dpsk_ocr_eval_batch.py',
            'run_dpsk_ocr_pdf_batch.py',
            'deepseek_ocr.py'
        ]
        
        # å…±äº«æ¨¡å—åˆ—è¡¨ï¼ˆè¢«å¤šä¸ªè„šæœ¬å…±åŒä½¿ç”¨ï¼‰
        self.shared_modules = [
            'deepseek_ocr.py',
            'process/image_process.py',
        ]
        
        # é…ç½®æ–‡ä»¶åˆ—è¡¨
        self.config_files = [
            'config.py',
            'config_image.py',
            'config_pdf.py',
            'config_batch.py',
            'config_pdf_batch.py'
        ]
        
        # OCRè„šæœ¬ä¸é…ç½®æ–‡ä»¶çš„æ˜ å°„å…³ç³»
        self.script_config_mapping = {
            'run_dpsk_ocr_image.py': 'config_image',
            'run_dpsk_ocr_pdf.py': 'config_pdf',
            'run_dpsk_ocr_eval_batch.py': 'config_batch',
            'run_dpsk_ocr_pdf_batch.py': 'config_pdf_batch',
        }
        
        # æ–°åˆ›å»ºçš„é…ç½®æ–‡ä»¶ï¼ˆç”¨äºæ¢å¤æ—¶åˆ é™¤ï¼‰
        self.created_config_files = [
            'config_image.py',
            'config_pdf.py',
            'config_batch.py',
            'config_pdf_batch.py'
        ]
        
        # æ–°åˆ›å»ºçš„ç›®å½•ï¼ˆç”¨äºæ¢å¤æ—¶å¯é€‰åˆ é™¤ï¼‰
        self.created_directories = [
            'input_image', 'output_image',
            'input_pdf', 'output_pdf',
            'input_batch', 'output_batch',
            'input_pdf_batch', 'output_pdf_batch',
            'input', 'output'
        ]
        
        # ä¿®å¤ç»Ÿè®¡
        self.stats = {
            'total_files': 0,
            'fixed_files': 0,
            'skipped_files': 0,
            'failed_files': 0,
            'fixes_applied': 0
        }
    
    def check_environment(self):
        """æ£€æŸ¥ç¯å¢ƒå’Œæ–‡ä»¶"""
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ” æ£€æŸ¥ç¯å¢ƒ{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}\n")
        
        # æ£€æŸ¥é¡¹ç›®è·¯å¾„
        if not self.project_path.exists():
            print(f"{Colors.RED}âŒ é”™è¯¯: é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {self.project_path}{Colors.RESET}")
            return False
        print(f"{Colors.GREEN}âœ“{Colors.RESET} é¡¹ç›®è·¯å¾„: {self.project_path}")
        
        # æ£€æŸ¥vllmè·¯å¾„
        if not self.vllm_path.exists():
            print(f"{Colors.RED}âŒ é”™è¯¯: vllmè·¯å¾„ä¸å­˜åœ¨: {self.vllm_path}{Colors.RESET}")
            return False
        print(f"{Colors.GREEN}âœ“{Colors.RESET} vLLMè·¯å¾„: {self.vllm_path}")
        
        # æ£€æŸ¥éœ€è¦ä¿®å¤çš„æ–‡ä»¶
        print(f"\n{Colors.BLUE}ğŸ“„ å¾…ä¿®å¤æ–‡ä»¶:{Colors.RESET}")
        existing_files = []
        for filename in self.files_to_fix:
            filepath = self.vllm_path / filename
            if filepath.exists():
                existing_files.append(filename)
                print(f"  {Colors.GREEN}âœ“{Colors.RESET} {filename}")
            else:
                print(f"  {Colors.YELLOW}âŠ˜{Colors.RESET} {filename} (ä¸å­˜åœ¨ï¼Œè·³è¿‡)")
        
        if not existing_files:
            print(f"\n{Colors.RED}âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°éœ€è¦ä¿®å¤çš„æ–‡ä»¶{Colors.RESET}")
            return False
        
        self.stats['total_files'] = len(existing_files)
        return True
    
    def create_backup(self, include_configs=True):
        """åˆ›å»ºå¤‡ä»½ï¼ˆåŒ…æ‹¬è„šæœ¬æ–‡ä»¶ã€å…±äº«æ¨¡å—å’Œé…ç½®æ–‡ä»¶ï¼‰"""
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ’¾ åˆ›å»ºå¤‡ä»½{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}\n")
        
        try:
            os.makedirs(self.backup_dir, exist_ok=True)
            print(f"{Colors.BLUE}å¤‡ä»½ç›®å½•: {self.backup_dir}{Colors.RESET}\n")
            
            backup_count = 0
            
            # å¤‡ä»½ OCR è„šæœ¬æ–‡ä»¶
            print(f"{Colors.CYAN}å¤‡ä»½è„šæœ¬æ–‡ä»¶:{Colors.RESET}")
            for filename in self.files_to_fix:
                src_file = self.vllm_path / filename
                if src_file.exists():
                    dst_file = self.backup_dir / filename
                    shutil.copy2(src_file, dst_file)
                    print(f"  {Colors.GREEN}âœ“{Colors.RESET} {filename}")
                    backup_count += 1
            
            # å¤‡ä»½å…±äº«æ¨¡å—
            print(f"\n{Colors.CYAN}å¤‡ä»½å…±äº«æ¨¡å—:{Colors.RESET}")
            for module_path in self.shared_modules:
                src_file = self.vllm_path / module_path
                if src_file.exists():
                    # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨ï¼ˆå¤„ç†å­ç›®å½•å¦‚ process/ï¼‰
                    dst_file = self.backup_dir / module_path
                    os.makedirs(dst_file.parent, exist_ok=True)
                    shutil.copy2(src_file, dst_file)
                    print(f"  {Colors.GREEN}âœ“{Colors.RESET} {module_path}")
                    backup_count += 1
            
            # å¤‡ä»½é…ç½®æ–‡ä»¶
            if include_configs:
                print(f"\n{Colors.CYAN}å¤‡ä»½é…ç½®æ–‡ä»¶:{Colors.RESET}")
                for filename in self.config_files:
                    src_file = self.vllm_path / filename
                    if src_file.exists():
                        dst_file = self.backup_dir / filename
                        shutil.copy2(src_file, dst_file)
                        print(f"  {Colors.GREEN}âœ“{Colors.RESET} {filename}")
                        backup_count += 1
                    else:
                        # è®°å½•åŸæœ¬ä¸å­˜åœ¨çš„é…ç½®æ–‡ä»¶ï¼ˆæ¢å¤æ—¶éœ€è¦åˆ é™¤ï¼‰
                        marker_file = self.backup_dir / f'.{filename}.not_exists'
                        marker_file.touch()
            
            # ä¿å­˜å¤‡ä»½å…ƒä¿¡æ¯
            meta_file = self.backup_dir / '.backup_meta.txt'
            with open(meta_file, 'w', encoding='utf-8') as f:
                f.write(f"backup_time={datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"backup_count={backup_count}\n")
                f.write(f"include_configs={include_configs}\n")
            
            print(f"\n{Colors.GREEN}âœ… å¤‡ä»½å®Œæˆï¼å…±å¤‡ä»½ {backup_count} ä¸ªæ–‡ä»¶{Colors.RESET}")
            return True
        except Exception as e:
            print(f"\n{Colors.RED}âŒ å¤‡ä»½å¤±è´¥: {e}{Colors.RESET}")
            return False
    
    def list_backups(self):
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½ç›®å½•"""
        backups = []
        if self.project_path.exists():
            for item in self.project_path.iterdir():
                if item.is_dir() and item.name.startswith('backup_'):
                    backups.append(item)
        return sorted(backups, reverse=True)  # æœ€æ–°çš„åœ¨å‰é¢
    
    def restore_from_backup(self, backup_dir=None):
        """ä»å¤‡ä»½æ¢å¤æ–‡ä»¶ï¼ˆæ¢å¤æ‰€æœ‰ä¿®æ”¹ï¼Œåˆ é™¤æ–°åˆ›å»ºçš„æ–‡ä»¶ï¼‰"""
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ”„ æ¢å¤å¤‡ä»½{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}\n")
        
        backups = self.list_backups()
        
        if not backups:
            print(f"{Colors.RED}âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¤‡ä»½ç›®å½•{Colors.RESET}")
            return False
        
        if backup_dir is None:
            # æ˜¾ç¤ºå¯ç”¨çš„å¤‡ä»½
            print(f"{Colors.BLUE}å¯ç”¨çš„å¤‡ä»½:{Colors.RESET}\n")
            for i, backup in enumerate(backups, 1):
                # è§£ææ—¶é—´æˆ³
                timestamp = backup.name.replace('backup_', '')
                try:
                    dt = datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
                    formatted_time = dt.strftime("%Y-%m-%d %H:%M:%S")
                except:
                    formatted_time = timestamp
                
                # è¯»å–å¤‡ä»½å…ƒä¿¡æ¯
                meta_file = backup / '.backup_meta.txt'
                file_count = "æœªçŸ¥"
                if meta_file.exists():
                    with open(meta_file, 'r') as f:
                        for line in f:
                            if line.startswith('backup_count='):
                                file_count = line.split('=')[1].strip()
                
                print(f"  {i}. {backup.name} ({formatted_time}, {file_count}ä¸ªæ–‡ä»¶)")
            
            print(f"\nè¯·é€‰æ‹©è¦æ¢å¤çš„å¤‡ä»½ç¼–å· (1-{len(backups)})ï¼Œç•™ç©ºå–æ¶ˆ: ", end='')
            choice = input().strip()
            
            if not choice:
                print(f"{Colors.YELLOW}âŠ˜{Colors.RESET} å·²å–æ¶ˆæ¢å¤æ“ä½œ")
                return False
            
            try:
                idx = int(choice) - 1
                if 0 <= idx < len(backups):
                    backup_dir = backups[idx]
                else:
                    print(f"{Colors.RED}âŒ æ— æ•ˆçš„é€‰æ‹©{Colors.RESET}")
                    return False
            except ValueError:
                print(f"{Colors.RED}âŒ æ— æ•ˆçš„è¾“å…¥{Colors.RESET}")
                return False
        
        print(f"\n{Colors.BLUE}ä»å¤‡ä»½æ¢å¤: {backup_dir}{Colors.RESET}\n")
        
        try:
            restored_count = 0
            deleted_count = 0
            
            # 1. æ¢å¤è„šæœ¬æ–‡ä»¶
            print(f"{Colors.CYAN}æ¢å¤è„šæœ¬æ–‡ä»¶:{Colors.RESET}")
            for filename in self.files_to_fix:
                backup_file = backup_dir / filename
                target_file = self.vllm_path / filename
                
                if backup_file.exists():
                    shutil.copy2(backup_file, target_file)
                    print(f"  {Colors.GREEN}âœ“{Colors.RESET} å·²æ¢å¤: {filename}")
                    restored_count += 1
            
            # 2. æ¢å¤å…±äº«æ¨¡å—
            print(f"\n{Colors.CYAN}æ¢å¤å…±äº«æ¨¡å—:{Colors.RESET}")
            for module_path in self.shared_modules:
                backup_file = backup_dir / module_path
                target_file = self.vllm_path / module_path
                
                if backup_file.exists():
                    shutil.copy2(backup_file, target_file)
                    print(f"  {Colors.GREEN}âœ“{Colors.RESET} å·²æ¢å¤: {module_path}")
                    restored_count += 1
                else:
                    # æ£€æŸ¥æ˜¯å¦æœ‰ .backup_shared æ–‡ä»¶
                    shared_backup = str(target_file) + '.backup_shared'
                    if os.path.exists(shared_backup):
                        shutil.copy2(shared_backup, target_file)
                        print(f"  {Colors.GREEN}âœ“{Colors.RESET} å·²ä» .backup_shared æ¢å¤: {module_path}")
                        restored_count += 1
            
            # 4. æ¢å¤é…ç½®æ–‡ä»¶
            print(f"\n{Colors.CYAN}æ¢å¤é…ç½®æ–‡ä»¶:{Colors.RESET}")
            for filename in self.config_files:
                backup_file = backup_dir / filename
                target_file = self.vllm_path / filename
                marker_file = backup_dir / f'.{filename}.not_exists'
                
                if marker_file.exists():
                    # åŸæœ¬ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼Œéœ€è¦åˆ é™¤
                    if target_file.exists():
                        os.remove(target_file)
                        print(f"  {Colors.YELLOW}âœ—{Colors.RESET} å·²åˆ é™¤ï¼ˆåŸæœ¬ä¸å­˜åœ¨ï¼‰: {filename}")
                        deleted_count += 1
                elif backup_file.exists():
                    shutil.copy2(backup_file, target_file)
                    print(f"  {Colors.GREEN}âœ“{Colors.RESET} å·²æ¢å¤: {filename}")
                    restored_count += 1
            
            # 5. è¯¢é—®æ˜¯å¦åˆ é™¤æ–°åˆ›å»ºçš„ç›®å½•
            print(f"\n{Colors.YELLOW}æ˜¯å¦åˆ é™¤æ–°åˆ›å»ºçš„è¾“å…¥è¾“å‡ºç›®å½•ï¼Ÿ(y/nï¼Œé»˜è®¤n): {Colors.RESET}", end='')
            delete_dirs = input().strip().lower() == 'y'
            
            if delete_dirs:
                print(f"\n{Colors.CYAN}åˆ é™¤æ–°åˆ›å»ºçš„ç›®å½•:{Colors.RESET}")
                for dirname in self.created_directories:
                    dir_path = self.vllm_path / dirname
                    if dir_path.exists() and dir_path.is_dir():
                        # åªåˆ é™¤ç©ºç›®å½•æˆ–è¯¢é—®ç¡®è®¤
                        if not any(dir_path.iterdir()):
                            shutil.rmtree(dir_path)
                            print(f"  {Colors.YELLOW}âœ—{Colors.RESET} å·²åˆ é™¤ç›®å½•: {dirname}/")
                        else:
                            print(f"  {Colors.YELLOW}âŠ˜{Colors.RESET} ç›®å½•éç©ºï¼Œè·³è¿‡: {dirname}/")
            
            print(f"\n{Colors.GREEN}{'='*70}{Colors.RESET}")
            print(f"{Colors.GREEN}âœ… æ¢å¤å®Œæˆï¼{Colors.RESET}")
            print(f"  æ¢å¤æ–‡ä»¶æ•°: {restored_count}")
            print(f"  åˆ é™¤æ–‡ä»¶æ•°: {deleted_count}")
            print(f"{Colors.GREEN}{'='*70}{Colors.RESET}")
            return True
                
        except Exception as e:
            print(f"\n{Colors.RED}âŒ æ¢å¤å¤±è´¥: {e}{Colors.RESET}")
            return False
    
    # ========================================================================
    # vLLM ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤æ–¹æ³•
    # ========================================================================
    
    def fix_vllm_imports_deepseek_ocr(self, filepath):
        """ä¿®å¤ deepseek_ocr.py ä¸­çš„ vLLM å¯¼å…¥å…¼å®¹æ€§"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # ä¿®å¤1: SamplingMetadata å¯¼å…¥
        old_import_1 = "from vllm.model_executor import SamplingMetadata"
        new_import_1 = """# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ SamplingMetadata å¯¼å…¥
# å°è¯•å¤šä¸ªå¯èƒ½çš„å¯¼å…¥è·¯å¾„ä»¥ç¡®ä¿å…¼å®¹æ€§
try:
    # æ–°ç‰ˆ vllm (0.6.0+): SamplingMetadata åœ¨ sampling_metadata å­æ¨¡å—ä¸­
    from vllm.model_executor.sampling_metadata import SamplingMetadata
except ImportError:
    try:
        # æ—§ç‰ˆ vllm: SamplingMetadata ç›´æ¥ä» model_executor å¯¼å…¥
        from vllm.model_executor import SamplingMetadata
    except ImportError:
        try:
            # æŸäº›ç‰ˆæœ¬: ä» sequence æ¨¡å—å¯¼å…¥
            from vllm.sequence import SamplingMetadata
        except ImportError:
            try:
                # v1 API: ä» v1.sample.metadata å¯¼å…¥
                from vllm.v1.sample.metadata import SamplingMetadata
            except ImportError:
                # å¦‚æœæ‰€æœ‰å¯¼å…¥éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
                raise ImportError(
                    "æ— æ³•å¯¼å…¥ SamplingMetadataã€‚è¯·æ£€æŸ¥ vllm ç‰ˆæœ¬ï¼Œ"
                    "å°è¯•çš„å¯¼å…¥è·¯å¾„ï¼š\\n"
                    "  - vllm.model_executor.sampling_metadata\\n"
                    "  - vllm.model_executor\\n"
                    "  - vllm.sequence\\n"
                    "  - vllm.v1.sample.metadata\\n"
                    "å»ºè®®ï¼špip install --upgrade vllm æˆ–æ£€æŸ¥ vllm ç‰ˆæœ¬å…¼å®¹æ€§"
                )"""
        
        if old_import_1 in content and "# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ SamplingMetadata å¯¼å…¥" not in content:
            content = content.replace(old_import_1, new_import_1)
            fixes.append('SamplingMetadata å¯¼å…¥å…¼å®¹')
        
        # ä¿®å¤2: set_default_torch_dtype å¯¼å…¥
        old_import_2 = "from vllm.model_executor.model_loader.utils import set_default_torch_dtype"
        new_import_2 = """# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ set_default_torch_dtype å¯¼å…¥
# æ³¨æ„ï¼šæ­¤å‡½æ•°åœ¨ä»£ç ä¸­å¯èƒ½æœªä½¿ç”¨ï¼Œä½†ä¿ç•™å¯¼å…¥ä»¥ä¿æŒå…¼å®¹æ€§
try:
    # æ–°ç‰ˆ vllm: set_default_torch_dtype åœ¨ utils.torch_utils ä¸­
    from vllm.utils.torch_utils import set_default_torch_dtype
except ImportError:
    try:
        # æ—§ç‰ˆ vllm: set_default_torch_dtype åœ¨ model_loader.utils ä¸­
        from vllm.model_executor.model_loader.utils import set_default_torch_dtype
    except ImportError:
        # å¦‚æœéƒ½å¤±è´¥ï¼Œå°è¯•ä»å…¶ä»–å¯èƒ½çš„ä½ç½®å¯¼å…¥
        try:
            from vllm.utils import set_default_torch_dtype
        except ImportError:
            # å¦‚æœæ‰€æœ‰å¯¼å…¥éƒ½å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªå ä½ç¬¦æˆ–ä½¿ç”¨ torch çš„é»˜è®¤è¡Œä¸º
            # ç”±äºä»£ç ä¸­å¯èƒ½æœªä½¿ç”¨æ­¤å‡½æ•°ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª no-op å‡½æ•°
            def set_default_torch_dtype(dtype):
                \"\"\"å ä½ç¬¦å‡½æ•°ï¼Œå¦‚æœå¯¼å…¥å¤±è´¥åˆ™ä½¿ç”¨æ­¤å‡½æ•°\"\"\"
                pass"""
        
        if old_import_2 in content and "# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ set_default_torch_dtype å¯¼å…¥" not in content:
            content = content.replace(old_import_2, new_import_2)
            fixes.append('set_default_torch_dtype å¯¼å…¥å…¼å®¹')
        
        # ä¿®å¤3: merge_multimodal_embeddings å¯¼å…¥
        old_import_3 = """from vllm.model_executor.models.utils import (AutoWeightsLoader, WeightsMapper, flatten_bn,
                    init_vllm_registered_model, maybe_prefix,
                    merge_multimodal_embeddings)"""
        new_import_3 = """# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„å¯¼å…¥
from vllm.model_executor.models.utils import (AutoWeightsLoader, WeightsMapper, flatten_bn,
                    init_vllm_registered_model, maybe_prefix)
# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ merge_multimodal_embeddings å¯¼å…¥
try:
    # æ—§ç‰ˆ vllm: merge_multimodal_embeddings æ˜¯å…¬å¼€å‡½æ•°
    from vllm.model_executor.models.utils import merge_multimodal_embeddings
except ImportError:
    try:
        # æ–°ç‰ˆ vllm: å¯èƒ½æ˜¯ç§æœ‰å‡½æ•° _merge_multimodal_embeddings
        from vllm.model_executor.models.utils import _merge_multimodal_embeddings as merge_multimodal_embeddings
    except ImportError:
        try:
            # æŸäº›ç‰ˆæœ¬: å¯èƒ½åœ¨å…¶ä»–ä½ç½®
            from vllm.multimodal.utils import merge_multimodal_embeddings
        except ImportError:
            # å¦‚æœæ‰€æœ‰å¯¼å…¥éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
            raise ImportError(
                "æ— æ³•å¯¼å…¥ merge_multimodal_embeddingsã€‚è¯·æ£€æŸ¥ vllm ç‰ˆæœ¬ï¼Œ"
                "å°è¯•çš„å¯¼å…¥è·¯å¾„ï¼š\\n"
                "  - vllm.model_executor.models.utils.merge_multimodal_embeddings\\n"
                "  - vllm.model_executor.models.utils._merge_multimodal_embeddings\\n"
                "  - vllm.multimodal.utils.merge_multimodal_embeddings\\n"
                "å»ºè®®ï¼špip install --upgrade vllm æˆ–æ£€æŸ¥ vllm ç‰ˆæœ¬å…¼å®¹æ€§"
            )"""
        
        if old_import_3 in content and "# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ merge_multimodal_embeddings å¯¼å…¥" not in content:
            content = content.replace(old_import_3, new_import_3)
            fixes.append('merge_multimodal_embeddings å¯¼å…¥å…¼å®¹')
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def fix_vllm_imports_run_scripts(self, filepath):
        """ä¿®å¤è¿è¡Œè„šæœ¬ä¸­çš„ vLLM å¯¼å…¥å…¼å®¹æ€§ (ModelRegistry)"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # ä¿®å¤ ModelRegistry å¯¼å…¥
        old_import = "from vllm.model_executor.models.registry import ModelRegistry"
        new_import = """# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ ModelRegistry å¯¼å…¥
try:
    from vllm.model_executor.models.registry import ModelRegistry
except ImportError:
    try:
        from vllm.model_executor.models import ModelRegistry
    except ImportError:
        from vllm.model_executor.model_loader import ModelRegistry"""
        
        if old_import in content and "# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ ModelRegistry å¯¼å…¥" not in content:
            content = content.replace(old_import, new_import)
            fixes.append('ModelRegistry å¯¼å…¥å…¼å®¹')
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def fix_vllm_imports_run_image(self, filepath):
        """ä¿®å¤ run_dpsk_ocr_image.py ä¸­çš„ vLLM å¯¼å…¥å…¼å®¹æ€§"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # ä¿®å¤ AsyncLLMEngine, AsyncEngineArgs, ModelRegistry å¯¼å…¥
        old_imports = """from vllm import AsyncLLMEngine, SamplingParams
from vllm.engine.arg_utils import AsyncEngineArgs
from vllm.model_executor.models.registry import ModelRegistry"""
        
        new_imports = """# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„å¯¼å…¥
try:
    from vllm import AsyncLLMEngine, SamplingParams
except ImportError:
    # æŸäº›ç‰ˆæœ¬çš„ AsyncLLMEngine å¯èƒ½åœ¨ä¸åŒä½ç½®
    from vllm.engine.async_llm_engine import AsyncLLMEngine
    from vllm import SamplingParams

try:
    from vllm.engine.arg_utils import AsyncEngineArgs
except ImportError:
    try:
        from vllm.engine.async_llm_engine import AsyncEngineArgs
    except ImportError:
        from vllm import AsyncEngineArgs

# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ ModelRegistry å¯¼å…¥
try:
    from vllm.model_executor.models.registry import ModelRegistry
except ImportError:
    try:
        from vllm.model_executor.models import ModelRegistry
    except ImportError:
        from vllm.model_executor.model_loader import ModelRegistry"""
        
        if old_imports in content and "# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„å¯¼å…¥" not in content:
            content = content.replace(old_imports, new_imports)
            fixes.append('AsyncLLMEngine/AsyncEngineArgs/ModelRegistry å¯¼å…¥å…¼å®¹')
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def fix_vllm_imports(self, filename):
        """ä¿®å¤å•ä¸ªæ–‡ä»¶çš„ vLLM å¯¼å…¥å…¼å®¹æ€§"""
        filepath = self.vllm_path / filename
        
        if not filepath.exists():
            return None
        
        print(f"\n{Colors.BLUE}ğŸ“ ä¿®å¤ vLLM å¯¼å…¥: {filename}{Colors.RESET}")
        
        try:
            if filename == 'deepseek_ocr.py':
                fixes = self.fix_vllm_imports_deepseek_ocr(filepath)
            elif filename == 'run_dpsk_ocr_image.py':
                fixes = self.fix_vllm_imports_run_image(filepath)
            elif filename in ['run_dpsk_ocr_pdf.py', 'run_dpsk_ocr_eval_batch.py', 'run_dpsk_ocr_pdf_batch.py']:
                fixes = self.fix_vllm_imports_run_scripts(filepath)
            else:
                fixes = None
            
            if fixes:
                self.stats['fixed_files'] += 1
                self.stats['fixes_applied'] += len(fixes)
                print(f"{Colors.GREEN}âœ“{Colors.RESET} å·²ä¿®å¤ ({len(fixes)} å¤„):")
                for fix in fixes:
                    print(f"  â€¢ {fix}")
                return True
            else:
                print(f"{Colors.YELLOW}âŠ˜{Colors.RESET} å·²æ˜¯æœ€æ–°æˆ–æ— éœ€ä¿®å¤ï¼Œè·³è¿‡")
                return False
        
        except Exception as e:
            self.stats['failed_files'] += 1
            print(f"{Colors.RED}âœ—{Colors.RESET} ä¿®å¤å¤±è´¥: {e}")
            return False
    
    # ========================================================================
    # T4 GPU ä¿®å¤æ–¹æ³•
    # ========================================================================
    
    def fix_run_dpsk_ocr_image(self, filepath):
        """ä¿®å¤ run_dpsk_ocr_image.py çš„ T4 å…¼å®¹æ€§"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # ä¿®å¤1: block_size
        if 'block_size=256,' in content and 'block_size=16,' not in content:
            content = content.replace(
                'block_size=256,',
                'block_size=16,  # T4 GPU ä¿®å¤: 256 ä¸æ”¯æŒï¼Œæ”¹ä¸º 16'
            )
            fixes.append('block_size: 256 â†’ 16')
        
        # ä¿®å¤2: dtype='half' (AsyncEngineArgs)
        pattern = r"(gpu_memory_utilization=0\.75,\s*)\n(\s*)\)"
        if re.search(pattern, content) and "dtype='half'" not in content:
            replacement = r"\1\n\2dtype='half',  # ä½¿ç”¨float16ä»¥æ”¯æŒcompute capability 7.5çš„GPU (å¦‚Tesla T4)\n\2)"
            content = re.sub(pattern, replacement, content)
            fixes.append("dtype='half' (AsyncEngineArgs)")
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def fix_run_dpsk_ocr_pdf(self, filepath):
        """ä¿®å¤ run_dpsk_ocr_pdf.py çš„ T4 å…¼å®¹æ€§"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # ä¿®å¤1: block_size
        if 'block_size=256,' in content and 'block_size=16,' not in content:
            content = content.replace(
                'block_size=256,',
                'block_size=16,  # T4 GPU ä¿®å¤: 256 ä¸æ”¯æŒï¼Œæ”¹ä¸º 16'
            )
            fixes.append('block_size: 256 â†’ 16')
        
        # ä¿®å¤2: å…ˆç¡®ä¿ disable_mm_preprocessor_cache=True åé¢æœ‰é€—å·
        if 'disable_mm_preprocessor_cache=True\n' in content:
            content = content.replace(
                'disable_mm_preprocessor_cache=True\n',
                'disable_mm_preprocessor_cache=True,\n'
            )
            fixes.append('æ·»åŠ é€—å·')
        
        # ä¿®å¤3: dtype='half' (LLM)
        pattern = r"(disable_mm_preprocessor_cache=True,)\n(\s*)\)"
        if re.search(pattern, content) and "dtype='half'" not in content:
            replacement = r"\1\n\2dtype='half',  # ä½¿ç”¨float16ä»¥æ”¯æŒcompute capability 7.5çš„GPU (å¦‚Tesla T4)\n\2)"
            content = re.sub(pattern, replacement, content)
            fixes.append("dtype='half' (LLM)")
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def fix_run_dpsk_ocr_eval_batch(self, filepath):
        """ä¿®å¤ run_dpsk_ocr_eval_batch.py çš„ T4 å…¼å®¹æ€§"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # ä¿®å¤1: block_size
        if 'block_size=256,' in content and 'block_size=16,' not in content:
            content = content.replace(
                'block_size=256,',
                'block_size=16,  # T4 GPU ä¿®å¤: 256 ä¸æ”¯æŒï¼Œæ”¹ä¸º 16'
            )
            fixes.append('block_size: 256 â†’ 16')
        
        # ä¿®å¤2: dtype='half' (LLM)
        pattern = r"(gpu_memory_utilization=0\.9,?\s*)\n(\s*)\)"
        if re.search(pattern, content) and "dtype='half'" not in content:
            replacement = r"\1\n\2dtype='half',  # ä½¿ç”¨float16ä»¥æ”¯æŒcompute capability 7.5çš„GPU (å¦‚Tesla T4)\n\2)"
            content = re.sub(pattern, replacement, content)
            fixes.append("dtype='half' (LLM)")
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def fix_run_dpsk_ocr_pdf_batch(self, filepath):
        """ä¿®å¤ run_dpsk_ocr_pdf_batch.py çš„ T4 å…¼å®¹æ€§"""
        return self.fix_run_dpsk_ocr_pdf(filepath)
    
    def fix_deepseek_ocr(self, filepath):
        """ä¿®å¤ deepseek_ocr.py çš„ T4 å…¼å®¹æ€§"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # ä¿®å¤1: è§†è§‰ç¼–ç å™¨ dtype è½¬æ¢
        old_code = """        self.sam_model = build_sam_vit_b()
        self.vision_model = build_clip_l()

        n_embed = 1280
        self.projector =  MlpProjector(Dict(projector_type="linear", input_dim=2048, n_embed=n_embed))
        self.tile_tag = config.tile_tag
        self.global_view_pos = config.global_view_pos
    
        # self.sam_model = torch.compile(self.sam_model, mode="reduce-overhead")
        # self.vision_model = torch.compile(self.vision_model, mode="reduce-overhead")
        # self.projector = torch.compile(self.projector, mode="max-autotune")"""
        
        new_code = """        self.sam_model = build_sam_vit_b()
        self.vision_model = build_clip_l()

        n_embed = 1280
        self.projector =  MlpProjector(Dict(projector_type="linear", input_dim=2048, n_embed=n_embed))
        self.tile_tag = config.tile_tag
        self.global_view_pos = config.global_view_pos
    
        # ä¿®å¤ T4 GPU å…¼å®¹æ€§ï¼šç¡®ä¿è§†è§‰ç¼–ç å™¨ä½¿ç”¨ä¸ä¸»æ¨¡å‹ç›¸åŒçš„ dtype
        # å½“æ¨¡å‹ä½¿ç”¨ float16 æ—¶ï¼Œè§†è§‰ç¼–ç å™¨ä¹Ÿéœ€è¦è½¬æ¢ä¸º float16
        target_dtype = model_config.dtype
        if target_dtype == torch.float16:
            self.sam_model = self.sam_model.to(dtype=torch.float16)
            self.vision_model = self.vision_model.to(dtype=torch.float16)
            self.projector = self.projector.to(dtype=torch.float16)
    
        # self.sam_model = torch.compile(self.sam_model, mode="reduce-overhead")
        # self.vision_model = torch.compile(self.vision_model, mode="reduce-overhead")
        # self.projector = torch.compile(self.projector, mode="max-autotune")"""
        
        if old_code in content and 'target_dtype' not in content:
            content = content.replace(old_code, new_code)
            fixes.append('è§†è§‰ç¼–ç å™¨ dtype è½¬æ¢')
        
        # ä¿®å¤2: è¾“å…¥æ•°æ® dtype è½¬æ¢
        old_pattern = r"(\s+)patches = images_crop\[jdx\]\[0\]\.to\(torch\.bfloat16\)\s*# batch_size = 1\n(\s+)image_ori = pixel_values\[jdx\]"
        
        if re.search(old_pattern, content) and 'model_dtype = next(self.sam_model.parameters()).dtype' not in content:
            new_pattern = r"\1# T4 GPU fix: ä½¿ç”¨æ¨¡å‹çš„å®é™… dtype è€Œä¸æ˜¯ç¡¬ç¼–ç  bfloat16\n\1model_dtype = next(self.sam_model.parameters()).dtype\n\1patches = images_crop[jdx][0].to(model_dtype) # batch_size = 1\n\2image_ori = pixel_values[jdx].to(model_dtype)"
            content = re.sub(old_pattern, new_pattern, content)
            fixes.append('è¾“å…¥æ•°æ® dtype åŠ¨æ€è½¬æ¢')
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def fix_t4_file(self, filename):
        """ä¿®å¤å•ä¸ªæ–‡ä»¶çš„ T4 å…¼å®¹æ€§"""
        filepath = self.vllm_path / filename
        
        if not filepath.exists():
            self.stats['skipped_files'] += 1
            return None
        
        print(f"\n{Colors.BLUE}ğŸ“ ä¿®å¤ T4 å…¼å®¹æ€§: {filename}{Colors.RESET}")
        
        try:
            if filename == 'run_dpsk_ocr_image.py':
                fixes = self.fix_run_dpsk_ocr_image(filepath)
            elif filename == 'run_dpsk_ocr_pdf.py':
                fixes = self.fix_run_dpsk_ocr_pdf(filepath)
            elif filename == 'run_dpsk_ocr_eval_batch.py':
                fixes = self.fix_run_dpsk_ocr_eval_batch(filepath)
            elif filename == 'run_dpsk_ocr_pdf_batch.py':
                fixes = self.fix_run_dpsk_ocr_pdf_batch(filepath)
            elif filename == 'deepseek_ocr.py':
                fixes = self.fix_deepseek_ocr(filepath)
            else:
                fixes = None
            
            if fixes:
                self.stats['fixed_files'] += 1
                self.stats['fixes_applied'] += len(fixes)
                print(f"{Colors.GREEN}âœ“{Colors.RESET} å·²ä¿®å¤ ({len(fixes)} å¤„):")
                for fix in fixes:
                    print(f"  â€¢ {fix}")
                return True
            else:
                self.stats['skipped_files'] += 1
                print(f"{Colors.YELLOW}âŠ˜{Colors.RESET} å·²æ˜¯æœ€æ–°ï¼Œè·³è¿‡")
                return False
        
        except Exception as e:
            self.stats['failed_files'] += 1
            print(f"{Colors.RED}âœ—{Colors.RESET} ä¿®å¤å¤±è´¥: {e}")
            return False
    
    def verify_fixes(self, verify_all=True, categories=None):
        """
        éªŒè¯ä¿®å¤çŠ¶æ€
        
        å‚æ•°:
            verify_all: æ˜¯å¦éªŒè¯æ‰€æœ‰åŠŸèƒ½
            categories: è¦éªŒè¯çš„åŠŸèƒ½åˆ—è¡¨ï¼Œå¯é€‰å€¼ï¼š
                - 't4': T4 GPU å…¼å®¹æ€§
                - 'vllm': vLLM ç‰ˆæœ¬å…¼å®¹æ€§
                - 'config': é…ç½®æ–‡ä»¶å¼•ç”¨
                - 'memory': å†…å­˜ä¼˜åŒ–
        """
        if categories is None:
            categories = ['t4', 'vllm', 'config', 'memory']
        
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ” éªŒè¯ä¿®å¤çŠ¶æ€{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}")
        
        all_results = {
            't4_fixes': [],
            'vllm_fixes': [],
            'config_refs': [],
            'config_files': [],
            'memory_fixes': []
        }
        
        section_num = 1
        
        # ========================================
        # 1. éªŒè¯ T4 GPU å…¼å®¹æ€§ä¿®å¤
        # ========================================
        if 't4' in categories:
            print(f"\n{Colors.BLUE}ã€{section_num}ã€‘T4 GPU å…¼å®¹æ€§ä¿®å¤çŠ¶æ€{Colors.RESET}")
            print("-" * 50)
            section_num += 1
            
            for filename in self.files_to_fix:
                filepath = self.vllm_path / filename
                if not filepath.exists():
                    continue
                
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if filename == 'deepseek_ocr.py':
                    checks = {
                        'target_dtypeï¼ˆè§†è§‰ç¼–ç å™¨ï¼‰': 'target_dtype' in content,
                        'model_dtypeï¼ˆè¾“å…¥æ•°æ®ï¼‰': 'model_dtype = next(self.sam_model' in content
                    }
                else:
                    checks = {
                        'block_size=16': 'block_size=16' in content,
                        "dtype='half'": "dtype='half'" in content
                    }
                
                all_passed = all(checks.values())
                is_original = not any(checks.values())
                
                if is_original:
                    status = f"{Colors.YELLOW}â—‹{Colors.RESET}"
                    status_text = "åŸå§‹æ–‡ä»¶"
                elif all_passed:
                    status = f"{Colors.GREEN}âœ“{Colors.RESET}"
                    status_text = "å·²ä¿®å¤"
                else:
                    status = f"{Colors.RED}âœ—{Colors.RESET}"
                    status_text = "éƒ¨åˆ†ä¿®å¤"
                
                print(f"  {status} {filename} ({status_text})")
                
                if not all_passed and not is_original:
                    for check, result in checks.items():
                        if not result:
                            print(f"      {Colors.RED}âœ—{Colors.RESET} {check}")
                
                all_results['t4_fixes'].append({
                    'filename': filename,
                    'passed': all_passed,
                    'is_original': is_original
                })
        
        # ========================================
        # 2. éªŒè¯ vLLM ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤
        # ========================================
        if 'vllm' in categories:
            print(f"\n{Colors.BLUE}ã€{section_num}ã€‘vLLM ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤çŠ¶æ€{Colors.RESET}")
            print("-" * 50)
            section_num += 1
            
            vllm_checks = {
                'deepseek_ocr.py': [
                    ('SamplingMetadataå…¼å®¹å¯¼å…¥', '# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ SamplingMetadata å¯¼å…¥'),
                    ('set_default_torch_dtypeå…¼å®¹å¯¼å…¥', '# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ set_default_torch_dtype å¯¼å…¥'),
                    ('merge_multimodal_embeddingså…¼å®¹å¯¼å…¥', '# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ merge_multimodal_embeddings å¯¼å…¥')
                ],
                'run_dpsk_ocr_image.py': [
                    ('AsyncLLMEngine/ModelRegistryå…¼å®¹å¯¼å…¥', '# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„å¯¼å…¥')
                ],
                'run_dpsk_ocr_pdf.py': [
                    ('ModelRegistryå…¼å®¹å¯¼å…¥', '# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ ModelRegistry å¯¼å…¥')
                ],
                'run_dpsk_ocr_eval_batch.py': [
                    ('ModelRegistryå…¼å®¹å¯¼å…¥', '# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ ModelRegistry å¯¼å…¥')
                ],
                'run_dpsk_ocr_pdf_batch.py': [
                    ('ModelRegistryå…¼å®¹å¯¼å…¥', '# å…¼å®¹æ—§ç‰ˆå’Œæ–°ç‰ˆ vllm çš„ ModelRegistry å¯¼å…¥')
                ]
            }
            
            for filename, checks in vllm_checks.items():
                filepath = self.vllm_path / filename
                if not filepath.exists():
                    continue
                
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                file_results = []
                for check_name, check_pattern in checks:
                    passed = check_pattern in content
                    file_results.append((check_name, passed))
                
                all_passed = all(r[1] for r in file_results)
                is_original = not any(r[1] for r in file_results)
                
                if is_original:
                    status = f"{Colors.YELLOW}â—‹{Colors.RESET}"
                    status_text = "åŸå§‹æ–‡ä»¶"
                elif all_passed:
                    status = f"{Colors.GREEN}âœ“{Colors.RESET}"
                    status_text = "å·²ä¿®å¤"
                else:
                    status = f"{Colors.RED}âœ—{Colors.RESET}"
                    status_text = "éƒ¨åˆ†ä¿®å¤"
                
                print(f"  {status} {filename} ({status_text})")
                
                if not all_passed and not is_original:
                    for check_name, passed in file_results:
                        if not passed:
                            print(f"      {Colors.RED}âœ—{Colors.RESET} {check_name}")
                
                all_results['vllm_fixes'].append({
                    'filename': filename,
                    'passed': all_passed,
                    'is_original': is_original
                })
        
        # ========================================
        # 3. éªŒè¯é…ç½®æ–‡ä»¶å¼•ç”¨
        # ========================================
        if 'config' in categories:
            print(f"\n{Colors.BLUE}ã€{section_num}ã€‘é…ç½®æ–‡ä»¶å¼•ç”¨çŠ¶æ€{Colors.RESET}")
            print("-" * 50)
            section_num += 1
            
            for script, expected_config in self.script_config_mapping.items():
                filepath = self.vllm_path / script
                if not filepath.exists():
                    print(f"  {Colors.YELLOW}âŠ˜{Colors.RESET} {script} (æ–‡ä»¶ä¸å­˜åœ¨)")
                    continue
                
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ£€æŸ¥å½“å‰ä½¿ç”¨çš„é…ç½®
                uses_expected = f'from {expected_config} import' in content
                uses_original = 'from config import' in content and f'from {expected_config}' not in content
                
                if uses_expected:
                    status = f"{Colors.GREEN}âœ“{Colors.RESET}"
                    config_used = expected_config
                    status_text = "ç‹¬ç«‹é…ç½®"
                elif uses_original:
                    status = f"{Colors.YELLOW}â—‹{Colors.RESET}"
                    config_used = "config"
                    status_text = "åŸå§‹é…ç½®"
                else:
                    status = f"{Colors.RED}?{Colors.RESET}"
                    config_used = "æœªçŸ¥"
                    status_text = "æœªçŸ¥"
                
                print(f"  {status} {script}")
                print(f"      å½“å‰é…ç½®: {config_used}.py ({status_text})")
                print(f"      æ¨èé…ç½®: {expected_config}.py")
                
                all_results['config_refs'].append({
                    'script': script,
                    'expected_config': expected_config,
                    'uses_expected': uses_expected,
                    'uses_original': uses_original
                })
            
            # éªŒè¯é…ç½®æ–‡ä»¶å­˜åœ¨æ€§
            print(f"\n  {Colors.CYAN}é…ç½®æ–‡ä»¶å­˜åœ¨æ€§:{Colors.RESET}")
            
            for config_file in self.config_files:
                filepath = self.vllm_path / config_file
                exists = filepath.exists()
                
                if exists:
                    status = f"{Colors.GREEN}âœ“{Colors.RESET}"
                else:
                    status = f"{Colors.RED}âœ—{Colors.RESET}"
                
                print(f"    {status} {config_file} {'(å­˜åœ¨)' if exists else '(ä¸å­˜åœ¨)'}")
                all_results['config_files'].append({
                    'filename': config_file,
                    'exists': exists
                })
        
        # ========================================
        # 4. éªŒè¯å†…å­˜ä¼˜åŒ–
        # ========================================
        if 'memory' in categories:
            print(f"\n{Colors.BLUE}ã€{section_num}ã€‘å†…å­˜ä¼˜åŒ–çŠ¶æ€{Colors.RESET}")
            print("-" * 50)
            section_num += 1
            
            memory_checks = {
                'run_dpsk_ocr_pdf_batch.py': [
                    ('cleanup_memory() å‡½æ•°', 'def cleanup_memory():'),
                    ('å…¨å±€å¤„ç†å™¨å•ä¾‹', 'def get_processor():'),
                    ('åˆ†æ‰¹å¤„ç† PAGE_BATCH_SIZE', 'PAGE_BATCH_SIZE'),
                    ('çº¿ç¨‹æ•°é™åˆ¶', 'min(NUM_WORKERS'),
                    ('PDFé—´å†…å­˜æ¸…ç†', '# æ¯å¤„ç†å®Œä¸€ä¸ªPDFå°±å¼ºåˆ¶æ¸…ç†å†…å­˜'),
                ],
                'run_dpsk_ocr_eval_batch.py': [
                    ('cleanup_memory() å‡½æ•°', 'def cleanup_memory():'),
                    ('å…¨å±€å¤„ç†å™¨å•ä¾‹', 'get_processor()'),
                    ('åˆ†æ‰¹å¤„ç† BATCH_SIZE', 'BATCH_SIZE'),
                ],
                'run_dpsk_ocr_pdf.py': [
                    ('cleanup_memory() å‡½æ•°', 'def cleanup_memory():'),
                    ('å…¨å±€å¤„ç†å™¨å•ä¾‹', 'get_processor()'),
                ],
                'run_dpsk_ocr_image.py': [
                    ('cleanup_memory() å‡½æ•°', 'def cleanup_memory():'),
                ],
            }
            
            for filename, checks in memory_checks.items():
                filepath = self.vllm_path / filename
                if not filepath.exists():
                    continue
                
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                file_results = []
                for check_name, check_pattern in checks:
                    passed = check_pattern in content
                    file_results.append((check_name, passed))
                
                passed_count = sum(1 for r in file_results if r[1])
                total_count = len(file_results)
                is_original = passed_count == 0
                all_passed = passed_count == total_count
                
                if is_original:
                    status = f"{Colors.YELLOW}â—‹{Colors.RESET}"
                    status_text = "æœªä¼˜åŒ–"
                elif all_passed:
                    status = f"{Colors.GREEN}âœ“{Colors.RESET}"
                    status_text = "å·²ä¼˜åŒ–"
                else:
                    status = f"{Colors.YELLOW}â–³{Colors.RESET}"
                    status_text = f"éƒ¨åˆ†ä¼˜åŒ– ({passed_count}/{total_count})"
                
                print(f"  {status} {filename} ({status_text})")
                
                if not all_passed and not is_original:
                    for check_name, passed in file_results:
                        if not passed:
                            print(f"      {Colors.RED}âœ—{Colors.RESET} {check_name}")
                
                all_results['memory_fixes'].append({
                    'filename': filename,
                    'passed': all_passed,
                    'is_original': is_original,
                    'passed_count': passed_count,
                    'total_count': total_count
                })
        
        # ========================================
        # æ€»ç»“
        # ========================================
        print(f"\n{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        print(f"{Colors.MAGENTA}ğŸ“Š éªŒè¯æ€»ç»“{Colors.RESET}")
        print(f"{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        
        # T4 ä¿®å¤çŠ¶æ€
        if 't4' in categories and all_results['t4_fixes']:
            t4_fixed = sum(1 for r in all_results['t4_fixes'] if r['passed'])
            t4_original = sum(1 for r in all_results['t4_fixes'] if r['is_original'])
            t4_total = len(all_results['t4_fixes'])
            print(f"\n  T4 GPU å…¼å®¹æ€§: {t4_fixed}/{t4_total} å·²ä¿®å¤, {t4_original} åŸå§‹æ–‡ä»¶")
        
        # vLLM ä¿®å¤çŠ¶æ€
        if 'vllm' in categories and all_results['vllm_fixes']:
            vllm_fixed = sum(1 for r in all_results['vllm_fixes'] if r['passed'])
            vllm_original = sum(1 for r in all_results['vllm_fixes'] if r['is_original'])
            vllm_total = len(all_results['vllm_fixes'])
            print(f"  vLLM å…¼å®¹æ€§:   {vllm_fixed}/{vllm_total} å·²ä¿®å¤, {vllm_original} åŸå§‹æ–‡ä»¶")
        
        # é…ç½®å¼•ç”¨çŠ¶æ€
        if 'config' in categories and all_results['config_refs']:
            config_correct = sum(1 for r in all_results['config_refs'] if r['uses_expected'])
            config_original = sum(1 for r in all_results['config_refs'] if r['uses_original'])
            config_total = len(all_results['config_refs'])
            print(f"  é…ç½®æ–‡ä»¶å¼•ç”¨: {config_correct}/{config_total} ä½¿ç”¨ç‹¬ç«‹é…ç½®, {config_original} ä½¿ç”¨åŸå§‹é…ç½®")
            
            # é…ç½®æ–‡ä»¶å­˜åœ¨æ€§
            config_exists = sum(1 for r in all_results['config_files'] if r['exists'])
            config_files_total = len(all_results['config_files'])
            print(f"  é…ç½®æ–‡ä»¶å­˜åœ¨: {config_exists}/{config_files_total}")
        
        # å†…å­˜ä¼˜åŒ–çŠ¶æ€
        if 'memory' in categories and all_results['memory_fixes']:
            mem_fixed = sum(1 for r in all_results['memory_fixes'] if r['passed'])
            mem_original = sum(1 for r in all_results['memory_fixes'] if r['is_original'])
            mem_total = len(all_results['memory_fixes'])
            print(f"  å†…å­˜ä¼˜åŒ–:      {mem_fixed}/{mem_total} å·²ä¼˜åŒ–, {mem_original} æœªä¼˜åŒ–")
        
        # æ•´ä½“çŠ¶æ€åˆ¤æ–­
        all_original = True
        all_fixed = True
        
        if 't4' in categories and all_results['t4_fixes']:
            t4_fixed = sum(1 for r in all_results['t4_fixes'] if r['passed'])
            t4_original = sum(1 for r in all_results['t4_fixes'] if r['is_original'])
            t4_total = len(all_results['t4_fixes'])
            if t4_original != t4_total:
                all_original = False
            if t4_fixed != t4_total:
                all_fixed = False
        
        if 'vllm' in categories and all_results['vllm_fixes']:
            vllm_fixed = sum(1 for r in all_results['vllm_fixes'] if r['passed'])
            vllm_original = sum(1 for r in all_results['vllm_fixes'] if r['is_original'])
            vllm_total = len(all_results['vllm_fixes'])
            if vllm_original != vllm_total:
                all_original = False
            if vllm_fixed != vllm_total:
                all_fixed = False
        
        if 'memory' in categories and all_results['memory_fixes']:
            mem_fixed = sum(1 for r in all_results['memory_fixes'] if r['passed'])
            mem_original = sum(1 for r in all_results['memory_fixes'] if r['is_original'])
            mem_total = len(all_results['memory_fixes'])
            if mem_original != mem_total:
                all_original = False
            if mem_fixed != mem_total:
                all_fixed = False
        
        if all_original:
            print(f"\n{Colors.YELLOW}âš ï¸  æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯åŸå§‹çŠ¶æ€ï¼Œå°šæœªåº”ç”¨ä»»ä½•ä¿®å¤{Colors.RESET}")
            return False
        elif all_fixed:
            print(f"\n{Colors.GREEN}âœ… æ‰€æœ‰ä¿®å¤å·²å®Œæˆï¼{Colors.RESET}")
            return True
        else:
            print(f"\n{Colors.YELLOW}âš ï¸  éƒ¨åˆ†ä¿®å¤å·²å®Œæˆï¼Œå»ºè®®è¿è¡Œå®Œæ•´ä¿®å¤{Colors.RESET}")
            return False
    
    def generate_report(self):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        print(f"\n{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        print(f"{Colors.MAGENTA}ğŸ“Š ä¿®å¤æŠ¥å‘Š{Colors.RESET}")
        print(f"{Colors.MAGENTA}{'='*70}{Colors.RESET}\n")
        
        print(f"{Colors.CYAN}ç»Ÿè®¡ä¿¡æ¯:{Colors.RESET}")
        print(f"  æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"  {Colors.GREEN}âœ“ å·²ä¿®å¤: {self.stats['fixed_files']}{Colors.RESET}")
        print(f"  {Colors.YELLOW}âŠ˜ å·²è·³è¿‡: {self.stats['skipped_files']}{Colors.RESET}")
        print(f"  {Colors.RED}âœ— ä¿®å¤å¤±è´¥: {self.stats['failed_files']}{Colors.RESET}")
        print(f"  ä¿®å¤æ€»æ•°: {self.stats['fixes_applied']} å¤„")
        
        print(f"\n{Colors.CYAN}å¤‡ä»½ä½ç½®:{Colors.RESET}")
        print(f"  {self.backup_dir}")
        
        print(f"\n{Colors.CYAN}ä¸‹ä¸€æ­¥:{Colors.RESET}")
        print(f"  1. éªŒè¯ä¿®å¤æ˜¯å¦ç”Ÿæ•ˆ")
        print(f"  2. åœ¨T4 GPUä¸Šæµ‹è¯•è¿è¡Œ")
        print(f"  3. å¦‚æœ‰é—®é¢˜ï¼Œä½¿ç”¨æ¢å¤åŠŸèƒ½æ¢å¤å¤‡ä»½")
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = self.project_path / f'fix_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("DeepSeek-OCR T4 GPU å…¼å®¹æ€§ä¿®å¤æŠ¥å‘Š\n")
            f.write("="*70 + "\n\n")
            f.write(f"ä¿®å¤æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"é¡¹ç›®è·¯å¾„: {self.project_path}\n")
            f.write(f"å¤‡ä»½è·¯å¾„: {self.backup_dir}\n\n")
            f.write("ç»Ÿè®¡ä¿¡æ¯:\n")
            f.write(f"  æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}\n")
            f.write(f"  å·²ä¿®å¤: {self.stats['fixed_files']}\n")
            f.write(f"  å·²è·³è¿‡: {self.stats['skipped_files']}\n")
            f.write(f"  ä¿®å¤å¤±è´¥: {self.stats['failed_files']}\n")
            f.write(f"  ä¿®å¤æ€»æ•°: {self.stats['fixes_applied']} å¤„\n")
        
        print(f"\n{Colors.GREEN}ğŸ“ æŠ¥å‘Šå·²ä¿å­˜: {report_file}{Colors.RESET}")
    
    def create_directories_and_update_config(self):
        """åˆ›å»ºè¾“å…¥è¾“å‡ºç›®å½•å¹¶æ›´æ–°config.py"""
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ“‚ åˆ›å»ºè¾“å…¥è¾“å‡ºç›®å½•{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}\n")
        
        try:
            input_dir = self.vllm_path / 'input'
            output_dir = self.vllm_path / 'output'
            
            os.makedirs(input_dir, exist_ok=True)
            os.makedirs(output_dir, exist_ok=True)
            
            print(f"{Colors.GREEN}âœ“{Colors.RESET} è¾“å…¥ç›®å½•: {input_dir}")
            print(f"{Colors.GREEN}âœ“{Colors.RESET} è¾“å‡ºç›®å½•: {output_dir}")
            
            config_path = self.vllm_path / 'config.py'
            if config_path.exists():
                print(f"\n{Colors.BLUE}æ›´æ–° config.py è·¯å¾„é…ç½®...{Colors.RESET}")
                
                with open(config_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                original_content = content
                
                input_path_str = str(input_dir).replace('\\', '/')
                output_path_str = str(output_dir).replace('\\', '/')
                
                if "INPUT_PATH = ''" in content or 'INPUT_PATH = ""' in content:
                    content = re.sub(
                        r"INPUT_PATH = ['\"].*?['\"]",
                        f"INPUT_PATH = '{input_path_str}'",
                        content
                    )
                    print(f"{Colors.GREEN}âœ“{Colors.RESET} å·²æ›´æ–° INPUT_PATH")
                
                if "OUTPUT_PATH = ''" in content or 'OUTPUT_PATH = ""' in content:
                    content = re.sub(
                        r"OUTPUT_PATH = ['\"].*?['\"]",
                        f"OUTPUT_PATH = '{output_path_str}'",
                        content
                    )
                    print(f"{Colors.GREEN}âœ“{Colors.RESET} å·²æ›´æ–° OUTPUT_PATH")
                
                if content != original_content:
                    with open(config_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                else:
                    print(f"{Colors.YELLOW}âŠ˜{Colors.RESET} è·¯å¾„å·²é…ç½®ï¼Œæ— éœ€æ›´æ–°")
            
            return True
        except Exception as e:
            print(f"{Colors.RED}âœ—{Colors.RESET} åˆ›å»ºç›®å½•å¤±è´¥: {e}")
            return False
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'total_files': 0,
            'fixed_files': 0,
            'skipped_files': 0,
            'failed_files': 0,
            'fixes_applied': 0
        }
    
    def show_menu(self):
        """æ˜¾ç¤ºäº¤äº’å¼èœå•"""
        print(f"\n{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}ğŸ”§ DeepSeek-OCR è‡ªåŠ¨ä¿®å¤å·¥å…· v3.0{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        
        print(f"\n{Colors.CYAN}è¯·é€‰æ‹©è¦æ‰§è¡Œçš„æ“ä½œ:{Colors.RESET}\n")
        print(f"  {Colors.GREEN}1{Colors.RESET}. å®Œæ•´ä¿®å¤ (T4 GPU + vLLM å…¼å®¹æ€§)")
        print(f"  {Colors.GREEN}2{Colors.RESET}. ä»…ä¿®å¤ T4 GPU å…¼å®¹æ€§é—®é¢˜")
        print(f"  {Colors.GREEN}3{Colors.RESET}. ä»…ä¿®å¤ vLLM ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜")
        print(f"  {Colors.GREEN}4{Colors.RESET}. æ¢å¤å¤‡ä»½ (æ’¤é”€æ‰€æœ‰ä¿®æ”¹)")
        print(f"  {Colors.GREEN}5{Colors.RESET}. éªŒè¯å½“å‰ä¿®å¤çŠ¶æ€")
        print(f"  {Colors.GREEN}6{Colors.RESET}. åˆ›å»ºç‹¬ç«‹é…ç½®æ–‡ä»¶ (å›¾ç‰‡/PDF/æ‰¹é‡)")
        print(f"  {Colors.GREEN}7{Colors.RESET}. æ·»åŠ å†…å­˜ä¼˜åŒ– (é˜²æ­¢OOMå´©æºƒ)")
        print(f"  {Colors.GREEN}0{Colors.RESET}. é€€å‡º")
        
        print(f"\n{Colors.YELLOW}æç¤º: ç›´æ¥æŒ‰å›è½¦å°†ä¸æ‰§è¡Œä»»ä½•ä¿®æ”¹{Colors.RESET}")
        print(f"\nè¯·è¾“å…¥é€‰é¡¹ (0-7): ", end='')
        
        return input().strip()
    
    def show_verify_menu(self):
        """æ˜¾ç¤ºéªŒè¯å­èœå•"""
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ” éªŒè¯ä¿®å¤çŠ¶æ€{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}")
        
        print(f"\n{Colors.CYAN}è¯·é€‰æ‹©è¦éªŒè¯çš„åŠŸèƒ½:{Colors.RESET}\n")
        print(f"  {Colors.GREEN}1{Colors.RESET}. éªŒè¯å…¨éƒ¨ (T4 + vLLM + é…ç½® + å†…å­˜)")
        print(f"  {Colors.GREEN}2{Colors.RESET}. ä»…éªŒè¯ T4 GPU å…¼å®¹æ€§ä¿®å¤")
        print(f"  {Colors.GREEN}3{Colors.RESET}. ä»…éªŒè¯ vLLM ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤")
        print(f"  {Colors.GREEN}4{Colors.RESET}. ä»…éªŒè¯é…ç½®æ–‡ä»¶çŠ¶æ€")
        print(f"  {Colors.GREEN}5{Colors.RESET}. ä»…éªŒè¯å†…å­˜ä¼˜åŒ–çŠ¶æ€")
        print(f"  {Colors.GREEN}0{Colors.RESET}. è¿”å›ä¸»èœå•")
        
        print(f"\nè¯·è¾“å…¥é€‰é¡¹ (0-5): ", end='')
        choice = input().strip()
        
        if choice == '1' or choice == '':
            self.verify_fixes(categories=['t4', 'vllm', 'config', 'memory'])
        elif choice == '2':
            self.verify_fixes(categories=['t4'])
        elif choice == '3':
            self.verify_fixes(categories=['vllm'])
        elif choice == '4':
            self.verify_fixes(categories=['config'])
        elif choice == '5':
            self.verify_fixes(categories=['memory'])
        elif choice == '0':
            return
        else:
            print(f"\n{Colors.RED}âŒ æ— æ•ˆçš„é€‰é¡¹{Colors.RESET}")
    
    def run_interactive(self):
        """äº¤äº’å¼è¿è¡Œä¿®å¤æµç¨‹"""
        while True:
            choice = self.show_menu()
            
            if choice == '' or choice == '0':
                print(f"\n{Colors.CYAN}ğŸ‘‹ é€€å‡ºç¨‹åº{Colors.RESET}\n")
                break
            
            elif choice == '1':
                # å®Œæ•´ä¿®å¤
                self.run_full_fix()
            
            elif choice == '2':
                # ä»… T4 GPU ä¿®å¤
                self.run_t4_fix_only()
            
            elif choice == '3':
                # ä»… vLLM å…¼å®¹æ€§ä¿®å¤
                self.run_vllm_fix_only()
            
            elif choice == '4':
                # æ¢å¤å¤‡ä»½
                self.restore_from_backup()
            
            elif choice == '5':
                # éªŒè¯çŠ¶æ€
                if self.check_environment():
                    self.show_verify_menu()
            
            elif choice == '6':
                # åˆ›å»ºç‹¬ç«‹é…ç½®æ–‡ä»¶
                self.create_separate_configs()
            
            elif choice == '7':
                # æ·»åŠ å†…å­˜ä¼˜åŒ–
                self.add_memory_optimization()
            
            else:
                print(f"\n{Colors.RED}âŒ æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©{Colors.RESET}")
            
            print(f"\n{Colors.CYAN}æŒ‰å›è½¦é”®ç»§ç»­...{Colors.RESET}")
            input()
    
    def run_full_fix(self):
        """è¿è¡Œå®Œæ•´ä¿®å¤ (T4 + vLLM)"""
        self.reset_stats()
        
        print(f"\n{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}ğŸ”§ å®Œæ•´ä¿®å¤ (T4 GPU + vLLM å…¼å®¹æ€§){Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        
        if not self.check_environment():
            return False
        
        if not self.create_backup():
            return False
        
        self.create_directories_and_update_config()
        
        # T4 GPU ä¿®å¤
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ”¨ å¼€å§‹ T4 GPU å…¼å®¹æ€§ä¿®å¤{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}")
        
        for filename in self.files_to_fix:
            self.fix_t4_file(filename)
        
        # vLLM å…¼å®¹æ€§ä¿®å¤
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ”¨ å¼€å§‹ vLLM ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}")
        
        for filename in self.files_to_fix:
            self.fix_vllm_imports(filename)
        
        self.verify_fixes()
        self.generate_report()
        
        return True
    
    def run_t4_fix_only(self):
        """ä»…è¿è¡Œ T4 GPU ä¿®å¤"""
        self.reset_stats()
        
        print(f"\n{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}ğŸ”§ T4 GPU å…¼å®¹æ€§ä¿®å¤{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        
        if not self.check_environment():
            return False
        
        if not self.create_backup():
            return False
        
        self.create_directories_and_update_config()
        
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ”¨ å¼€å§‹ T4 GPU å…¼å®¹æ€§ä¿®å¤{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}")
        
        for filename in self.files_to_fix:
            self.fix_t4_file(filename)
        
        self.verify_fixes()
        self.generate_report()
        
        return True
    
    def run_vllm_fix_only(self):
        """ä»…è¿è¡Œ vLLM å…¼å®¹æ€§ä¿®å¤"""
        self.reset_stats()
        
        print(f"\n{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}ğŸ”§ vLLM ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        
        if not self.check_environment():
            return False
        
        if not self.create_backup():
            return False
        
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ”¨ å¼€å§‹ vLLM ç‰ˆæœ¬å…¼å®¹æ€§ä¿®å¤{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}")
        
        for filename in self.files_to_fix:
            self.fix_vllm_imports(filename)
        
        self.generate_report()
        
        return True
    
    # ========================================================================
    # åˆ›å»ºç‹¬ç«‹é…ç½®æ–‡ä»¶åŠŸèƒ½
    # ========================================================================
    
    def create_separate_configs(self):
        """åˆ›å»ºç‹¬ç«‹çš„é…ç½®æ–‡ä»¶ï¼ˆå›¾ç‰‡/PDF/æ‰¹é‡ï¼‰å¹¶æ›´æ–°è„šæœ¬å¼•ç”¨"""
        print(f"\n{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}ğŸ“ åˆ›å»ºç‹¬ç«‹é…ç½®æ–‡ä»¶{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        
        if not self.vllm_path.exists():
            print(f"\n{Colors.RED}âŒ é”™è¯¯: vLLM è·¯å¾„ä¸å­˜åœ¨: {self.vllm_path}{Colors.RESET}")
            return False
        
        config_file = self.vllm_path / 'config.py'
        if not config_file.exists():
            print(f"\n{Colors.RED}âŒ é”™è¯¯: config.py ä¸å­˜åœ¨{Colors.RESET}")
            return False
        
        # åˆ›å»ºå¤‡ä»½ï¼ˆåŒ…æ‹¬å½“å‰çš„é…ç½®æ–‡ä»¶å’Œè„šæœ¬æ–‡ä»¶ï¼‰
        if not self.create_backup(include_configs=True):
            return False
        
        # è¯»å–åŸå§‹ config.py
        with open(config_file, 'r', encoding='utf-8') as f:
            original_config = f.read()
        
        print(f"\n{Colors.BLUE}ğŸ“„ è¯»å–åŸå§‹é…ç½®æ–‡ä»¶: config.py{Colors.RESET}")
        
        # é…ç½®æ–‡ä»¶å®šä¹‰
        config_definitions = {
            'config_image.py': {
                'description': 'å•å¼ å›¾ç‰‡å¤„ç†é…ç½®',
                'input_dir': 'input_image',
                'output_dir': 'output_image',
                'script': 'run_dpsk_ocr_image.py',
                'header': '''"""
DeepSeek-OCR å•å¼ å›¾ç‰‡å¤„ç†é…ç½®æ–‡ä»¶
=================================

ä¸“ç”¨äº run_dpsk_ocr_image.py è„šæœ¬çš„é…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
    åœ¨ run_dpsk_ocr_image.py ä¸­å¯¼å…¥ï¼š
    from config_image import *

ä½œè€…ï¼šDeepSeek AI
ä¿®æ”¹æ—¥æœŸï¼š{date}
ç‰ˆæœ¬ï¼šv1.0
"""

import os
from pathlib import Path

''',
                'path_section': '''
# ============================================================================
# è¾“å…¥è¾“å‡ºè·¯å¾„ - å•å¼ å›¾ç‰‡å¤„ç†
# ============================================================================
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
CURRENT_DIR = Path(__file__).parent

# è¾“å…¥ï¼šå•å¼ å›¾ç‰‡æ–‡ä»¶æˆ–å›¾ç‰‡ç›®å½•
INPUT_DIR = CURRENT_DIR / '{input_dir}'
INPUT_PATH = str(INPUT_DIR)

# å¦‚æœæƒ³æŒ‡å®šå…·ä½“å›¾ç‰‡ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼š
# INPUT_PATH = str(INPUT_DIR / 'test_image.jpg')

# è¾“å‡ºï¼šç»“æœä¿å­˜ç›®å½•
OUTPUT_DIR = CURRENT_DIR / '{output_dir}'
OUTPUT_PATH = str(OUTPUT_DIR)

# è‡ªåŠ¨åˆ›å»ºç›®å½•
os.makedirs(INPUT_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR / 'images', exist_ok=True)

'''
            },
            'config_pdf.py': {
                'description': 'PDFæ–‡æ¡£å¤„ç†é…ç½®',
                'input_dir': 'input_pdf',
                'output_dir': 'output_pdf',
                'script': 'run_dpsk_ocr_pdf.py',
                'header': '''"""
DeepSeek-OCR PDFæ–‡æ¡£å¤„ç†é…ç½®æ–‡ä»¶
================================

ä¸“ç”¨äº run_dpsk_ocr_pdf.py è„šæœ¬çš„é…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
    åœ¨ run_dpsk_ocr_pdf.py ä¸­å¯¼å…¥ï¼š
    from config_pdf import *

ä½œè€…ï¼šDeepSeek AI
ä¿®æ”¹æ—¥æœŸï¼š{date}
ç‰ˆæœ¬ï¼šv1.0
"""

import os
from pathlib import Path

''',
                'path_section': '''
# ============================================================================
# è¾“å…¥è¾“å‡ºè·¯å¾„ - PDFæ–‡æ¡£å¤„ç†
# ============================================================================
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
CURRENT_DIR = Path(__file__).parent

# è¾“å…¥ï¼šPDFæ–‡ä»¶è·¯å¾„
INPUT_DIR = CURRENT_DIR / '{input_dir}'
INPUT_PATH = str(INPUT_DIR)

# å¦‚æœæ˜¯å•ä¸ªPDFï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶æŒ‡å®šæ–‡ä»¶ï¼š
# INPUT_PATH = str(INPUT_DIR / 'document.pdf')

# è¾“å‡ºï¼šç»“æœä¿å­˜ç›®å½•
OUTPUT_DIR = CURRENT_DIR / '{output_dir}'
OUTPUT_PATH = str(OUTPUT_DIR)

# è‡ªåŠ¨åˆ›å»ºç›®å½•
os.makedirs(INPUT_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

'''
            },
            'config_batch.py': {
                'description': 'æ‰¹é‡å›¾ç‰‡å¤„ç†é…ç½®',
                'input_dir': 'input_batch',
                'output_dir': 'output_batch',
                'script': 'run_dpsk_ocr_eval_batch.py',
                'header': '''"""
DeepSeek-OCR æ‰¹é‡å›¾ç‰‡å¤„ç†é…ç½®æ–‡ä»¶
=================================

ä¸“ç”¨äº run_dpsk_ocr_eval_batch.py è„šæœ¬çš„é…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
    åœ¨ run_dpsk_ocr_eval_batch.py ä¸­å¯¼å…¥ï¼š
    from config_batch import *

ä½œè€…ï¼šDeepSeek AI
ä¿®æ”¹æ—¥æœŸï¼š{date}
ç‰ˆæœ¬ï¼šv1.0
"""

import os
from pathlib import Path

''',
                'path_section': '''
# ============================================================================
# è¾“å…¥è¾“å‡ºè·¯å¾„ - æ‰¹é‡å›¾ç‰‡å¤„ç†
# ============================================================================
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
CURRENT_DIR = Path(__file__).parent

# è¾“å…¥ï¼šåŒ…å«å¤šå¼ å›¾ç‰‡çš„æ–‡ä»¶å¤¹
INPUT_DIR = CURRENT_DIR / '{input_dir}'
INPUT_PATH = str(INPUT_DIR)

# è¾“å‡ºï¼šç»“æœä¿å­˜ç›®å½•
OUTPUT_DIR = CURRENT_DIR / '{output_dir}'
OUTPUT_PATH = str(OUTPUT_DIR)

# è‡ªåŠ¨åˆ›å»ºç›®å½•
os.makedirs(INPUT_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

'''
            },
            'config_pdf_batch.py': {
                'description': 'æ‰¹é‡PDFå¤„ç†é…ç½®',
                'input_dir': 'input_pdf_batch',
                'output_dir': 'output_pdf_batch',
                'script': 'run_dpsk_ocr_pdf_batch.py',
                'header': '''"""
DeepSeek-OCR æ‰¹é‡PDFå¤„ç†é…ç½®æ–‡ä»¶
================================

ä¸“ç”¨äº run_dpsk_ocr_pdf_batch.py è„šæœ¬çš„é…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
    åœ¨ run_dpsk_ocr_pdf_batch.py ä¸­å¯¼å…¥ï¼š
    from config_pdf_batch import *

ä½œè€…ï¼šDeepSeek AI
ä¿®æ”¹æ—¥æœŸï¼š{date}
ç‰ˆæœ¬ï¼šv1.0
"""

import os
from pathlib import Path

''',
                'path_section': '''
# ============================================================================
# è¾“å…¥è¾“å‡ºè·¯å¾„ - æ‰¹é‡PDFå¤„ç†
# ============================================================================
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
CURRENT_DIR = Path(__file__).parent

# è¾“å…¥ï¼šåŒ…å«å¤šä¸ªPDFæ–‡ä»¶çš„æ–‡ä»¶å¤¹
INPUT_DIR = CURRENT_DIR / '{input_dir}'
INPUT_PATH = str(INPUT_DIR)

# è¾“å‡ºï¼šç»“æœä¿å­˜ç›®å½•ï¼ˆæ¯ä¸ªPDFä¼šåˆ›å»ºå­ç›®å½•ï¼‰
OUTPUT_DIR = CURRENT_DIR / '{output_dir}'
OUTPUT_PATH = str(OUTPUT_DIR)

# è‡ªåŠ¨åˆ›å»ºç›®å½•
os.makedirs(INPUT_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

'''
            }
        }
        
        # ä»åŸå§‹ config.py æå–æ ¸å¿ƒé…ç½®éƒ¨åˆ†
        core_config = self._extract_core_config(original_config)
        
        created_configs = []
        
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ“ åˆ›å»ºé…ç½®æ–‡ä»¶{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}\n")
        
        for config_name, config_def in config_definitions.items():
            config_path = self.vllm_path / config_name
            
            # ç”Ÿæˆé…ç½®æ–‡ä»¶å†…å®¹
            date_str = datetime.now().strftime('%Y-%m-%d')
            header = config_def['header'].format(date=date_str)
            path_section = config_def['path_section'].format(
                input_dir=config_def['input_dir'],
                output_dir=config_def['output_dir']
            )
            
            # ç»„åˆé…ç½®æ–‡ä»¶
            config_content = header + core_config + path_section
            
            # æ·»åŠ åˆ†è¯å™¨åˆå§‹åŒ–
            config_content += '''
# ============================================================================
# åˆ†è¯å™¨åˆå§‹åŒ–
# ============================================================================
from transformers import AutoTokenizer

TOKENIZER = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
'''
            
            # å†™å…¥é…ç½®æ–‡ä»¶
            with open(config_path, 'w', encoding='utf-8') as f:
                f.write(config_content)
            
            # åˆ›å»ºç›®å½•
            input_dir = self.vllm_path / config_def['input_dir']
            output_dir = self.vllm_path / config_def['output_dir']
            os.makedirs(input_dir, exist_ok=True)
            os.makedirs(output_dir, exist_ok=True)
            
            print(f"{Colors.GREEN}âœ“{Colors.RESET} å·²åˆ›å»º: {config_name} ({config_def['description']})")
            print(f"  è¾“å…¥ç›®å½•: {config_def['input_dir']}/")
            print(f"  è¾“å‡ºç›®å½•: {config_def['output_dir']}/")
            
            created_configs.append({
                'config': config_name,
                'script': config_def['script'],
                'description': config_def['description']
            })
        
        # è¯¢é—®æ˜¯å¦æ›´æ–°è„šæœ¬å¼•ç”¨
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ”— æ›´æ–°è„šæœ¬é…ç½®å¼•ç”¨{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}\n")
        
        print(f"{Colors.YELLOW}æ˜¯å¦æ›´æ–°è¿è¡Œè„šæœ¬çš„é…ç½®å¼•ç”¨ï¼Ÿ{Colors.RESET}")
        print(f"  è¿™å°†ä¿®æ”¹ä»¥ä¸‹è„šæœ¬ï¼š")
        for item in created_configs:
            print(f"    â€¢ {item['script']} â†’ from {item['config'].replace('.py', '')} import ...")
        
        print(f"\nè¾“å…¥ 'y' ç¡®è®¤æ›´æ–°ï¼Œå…¶ä»–è¾“å…¥è·³è¿‡: ", end='')
        confirm = input().strip().lower()
        
        if confirm == 'y':
            self._update_script_config_imports(created_configs)
        else:
            print(f"{Colors.YELLOW}âŠ˜{Colors.RESET} è·³è¿‡æ›´æ–°è„šæœ¬å¼•ç”¨")
            print(f"\n{Colors.CYAN}ğŸ’¡ æ‰‹åŠ¨æ›´æ–°æ–¹æ³•:{Colors.RESET}")
            for item in created_configs:
                config_module = item['config'].replace('.py', '')
                print(f"  åœ¨ {item['script']} ä¸­å°†:")
                print(f"    from config import ... â†’ from {config_module} import ...")
        
        print(f"\n{Colors.GREEN}âœ… é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆï¼{Colors.RESET}")
        return True
    
    def _extract_core_config(self, config_content):
        """ä»åŸå§‹ config.py æå–æ ¸å¿ƒé…ç½®éƒ¨åˆ†"""
        # æå–æ¨¡å‹è§„æ ¼é…ç½®åˆ°æç¤ºè¯é…ç½®ä¹‹é—´çš„å†…å®¹
        core_sections = []
        
        # æå–æ¨¡å‹è§„æ ¼é…ç½®
        model_spec_pattern = r'(# ={70,}\n# æ¨¡å‹è§„æ ¼é…ç½®.*?(?=# ={70,}\n# è¾“å…¥è¾“å‡ºè·¯å¾„|# ={70,}\n# åˆ†è¯å™¨))'
        model_spec_match = re.search(model_spec_pattern, config_content, re.DOTALL)
        if model_spec_match:
            core_sections.append(model_spec_match.group(1))
        else:
            # å¤‡ç”¨ï¼šæå–åŸºæœ¬å˜é‡
            core_sections.append('''# ============================================================================
# æ¨¡å‹è§„æ ¼é…ç½®
# ============================================================================
BASE_SIZE = 1024      # åŸºç¡€å›¾åƒå¤§å°ï¼ˆå…¨å±€è§†å›¾ï¼‰
IMAGE_SIZE = 640      # è£å‰ªå›¾åƒå¤§å°ï¼ˆå±€éƒ¨è§†å›¾ï¼‰
CROP_MODE = True      # æ˜¯å¦å¯ç”¨å›¾åƒè£å‰ªæ¨¡å¼

# ============================================================================
# è£å‰ªé…ç½®
# ============================================================================
MIN_CROPS = 2         # æœ€å°è£å‰ªæ•°é‡
MAX_CROPS = 6         # æœ€å¤§è£å‰ªæ•°é‡

# ============================================================================
# å¹¶å‘å’Œæ€§èƒ½é…ç½®
# ============================================================================
MAX_CONCURRENCY = 100 # æœ€å¤§å¹¶å‘å¤„ç†æ•°é‡
NUM_WORKERS = 64      # å›¾åƒé¢„å¤„ç†å·¥ä½œçº¿ç¨‹æ•°

# ============================================================================
# è°ƒè¯•å’Œè¾“å‡ºé…ç½®
# ============================================================================
PRINT_NUM_VIS_TOKENS = False  # æ˜¯å¦æ‰“å°è§†è§‰ token æ•°é‡
SKIP_REPEAT = True            # æ˜¯å¦è·³è¿‡é‡å¤å†…å®¹

# ============================================================================
# æ¨¡å‹è·¯å¾„é…ç½®
# ============================================================================
MODEL_PATH = 'deepseek-ai/DeepSeek-OCR'

# ============================================================================
# æç¤ºè¯é…ç½®
# ============================================================================
PROMPT = '<image>\\n<|grounding|>Convert the document to markdown.'

''')
        
        return ''.join(core_sections)
    
    def _update_script_config_imports(self, config_mappings):
        """æ›´æ–°è¿è¡Œè„šæœ¬å’Œå…±äº«æ¨¡å—ä¸­çš„é…ç½®å¯¼å…¥"""
        
        # ä¸»è„šæœ¬åˆ°é…ç½®æ–‡ä»¶çš„æ˜ å°„
        script_import_map = {
            'run_dpsk_ocr_image.py': 'config_image',
            'run_dpsk_ocr_pdf.py': 'config_pdf',
            'run_dpsk_ocr_eval_batch.py': 'config_batch',
            'run_dpsk_ocr_pdf_batch.py': 'config_pdf_batch',
        }
        
        # å…±äº«æ¨¡å—åˆ—è¡¨ï¼ˆè¿™äº›æ¨¡å—ä¹Ÿéœ€è¦æ›´æ–°å¯¼å…¥ï¼‰
        shared_modules = [
            'deepseek_ocr.py',
            'process/image_process.py',
        ]
        
        print(f"\n{Colors.BLUE}æ›´æ–°ä¸»è„šæœ¬é…ç½®å¯¼å…¥...{Colors.RESET}")
        
        for script_name, config_module in script_import_map.items():
            script_path = self.vllm_path / script_name
            
            if not script_path.exists():
                print(f"  {Colors.YELLOW}âŠ˜{Colors.RESET} è„šæœ¬ä¸å­˜åœ¨: {script_name}")
                continue
            
            with open(script_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›¿æ¢å¯¼å…¥è¯­å¥
            pattern = r'from\s+config\s+import\s+'
            if re.search(pattern, content) and f'from {config_module} import' not in content:
                new_content = re.sub(pattern, f'from {config_module} import ', content)
                
                with open(script_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                print(f"  {Colors.GREEN}âœ“{Colors.RESET} {script_name} â†’ {config_module}")
            else:
                print(f"  {Colors.YELLOW}âŠ˜{Colors.RESET} {script_name} å·²æ˜¯æœ€æ–°æˆ–æ— éœ€æ›´æ–°")
        
        # è¯¢é—®æ˜¯å¦æ›´æ–°å…±äº«æ¨¡å—
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.YELLOW}âš ï¸  å…³äºå…±äº«æ¨¡å—çš„é‡è¦è¯´æ˜ï¼š{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"""
å…±äº«æ¨¡å— (deepseek_ocr.py, process/image_process.py) è¢«æ‰€æœ‰è„šæœ¬å…±åŒä½¿ç”¨ã€‚
å¦‚æœå°†å®ƒä»¬æ”¹ä¸ºä½¿ç”¨ç‰¹å®šé…ç½®æ–‡ä»¶ï¼Œå…¶ä»–è„šæœ¬å°†æ— æ³•æ­£å¸¸å·¥ä½œã€‚

{Colors.GREEN}æ¨èæ–¹æ¡ˆï¼š{Colors.RESET}
  â€¢ ä¿æŒå…±äº«æ¨¡å—ä½¿ç”¨ config.py
  â€¢ åªéœ€ç¡®ä¿ config.py ä¸­çš„ MODEL_PATH æ­£ç¡®å³å¯
  â€¢ å„ä¸“ç”¨é…ç½®æ–‡ä»¶ä¸»è¦ç”¨äºè®¾ç½®ä¸åŒçš„è¾“å…¥/è¾“å‡ºè·¯å¾„

{Colors.YELLOW}å¦‚æœæ‚¨ç¡®å®éœ€è¦ä¸ºæ¯ä¸ªè„šæœ¬ä½¿ç”¨å®Œå…¨ç‹¬ç«‹çš„é…ç½®ï¼š{Colors.RESET}
  â€¢ éœ€è¦ä¸ºæ¯ä¸ªè„šæœ¬åˆ›å»ºç‹¬ç«‹çš„å…±äº«æ¨¡å—å‰¯æœ¬
  â€¢ è¿™ä¼šå¢åŠ ç»´æŠ¤å¤æ‚åº¦

æ˜¯å¦åŒæ­¥æ›´æ–°å…±äº«æ¨¡å—ï¼Ÿ(ä¸æ¨è)
  è¾“å…¥ 'shared' æ›´æ–°å…±äº«æ¨¡å—ä¸ºä½¿ç”¨å½“å‰é€‰æ‹©çš„é…ç½®
  è¾“å…¥å…¶ä»–ä»»æ„å†…å®¹è·³è¿‡ï¼ˆæ¨èï¼‰
""")
        print(f"è¯·è¾“å…¥: ", end='')
        user_input = input().strip().lower()
        
        if user_input == 'shared':
            print(f"\n{Colors.YELLOW}âš ï¸  è­¦å‘Šï¼šè¿™å°†å½±å“æ‰€æœ‰è„šæœ¬çš„è¿è¡Œï¼{Colors.RESET}")
            print(f"è¯·é€‰æ‹©è¦ä½¿ç”¨çš„é…ç½®æ–‡ä»¶ï¼š")
            print(f"  1. config_image (å•å›¾ç‰‡)")
            print(f"  2. config_pdf (PDF)")
            print(f"  3. config_batch (æ‰¹é‡å›¾ç‰‡)")
            print(f"  4. config_pdf_batch (æ‰¹é‡PDF)")
            print(f"\nè¾“å…¥æ•°å­— (1-4): ", end='')
            
            config_choice = input().strip()
            config_map = {
                '1': 'config_image',
                '2': 'config_pdf',
                '3': 'config_batch',
                '4': 'config_pdf_batch'
            }
            
            if config_choice in config_map:
                target_config = config_map[config_choice]
                self._update_shared_modules(shared_modules, target_config)
            else:
                print(f"{Colors.YELLOW}âŠ˜{Colors.RESET} æ— æ•ˆé€‰æ‹©ï¼Œè·³è¿‡æ›´æ–°å…±äº«æ¨¡å—")
        else:
            print(f"{Colors.GREEN}âœ“{Colors.RESET} ä¿æŒå…±äº«æ¨¡å—ä½¿ç”¨ config.pyï¼ˆæ¨èï¼‰")
            print(f"\n{Colors.CYAN}ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿ config.py ä¸­çš„ MODEL_PATH è®¾ç½®æ­£ç¡®{Colors.RESET}")
    
    def _update_shared_modules(self, modules, target_config):
        """æ›´æ–°å…±äº«æ¨¡å—çš„é…ç½®å¯¼å…¥"""
        print(f"\n{Colors.BLUE}æ›´æ–°å…±äº«æ¨¡å—é…ç½®å¯¼å…¥ â†’ {target_config}...{Colors.RESET}")
        
        for module_path in modules:
            full_path = self.vllm_path / module_path
            
            if not full_path.exists():
                print(f"  {Colors.YELLOW}âŠ˜{Colors.RESET} æ¨¡å—ä¸å­˜åœ¨: {module_path}")
                continue
            
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_path = str(full_path) + '.backup_shared'
            if not os.path.exists(backup_path):
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.write(content)
            
            # æ›¿æ¢å¯¼å…¥è¯­å¥
            pattern = r'from\s+config\s+import\s+'
            if re.search(pattern, content):
                new_content = re.sub(pattern, f'from {target_config} import ', content)
                
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                print(f"  {Colors.GREEN}âœ“{Colors.RESET} {module_path} â†’ {target_config}")
            else:
                print(f"  {Colors.YELLOW}âŠ˜{Colors.RESET} {module_path} æœªæ‰¾åˆ° config å¯¼å…¥")
        
        print(f"\n{Colors.YELLOW}âš ï¸  æ³¨æ„ï¼šå…±äº«æ¨¡å—å·²æ›´æ–°ï¼{Colors.RESET}")
        print(f"  å¦‚éœ€æ¢å¤ï¼Œè¯·ä½¿ç”¨åŠŸèƒ½ 4ï¼ˆæ¢å¤å¤‡ä»½ï¼‰æˆ–æ‰‹åŠ¨æ¢å¤ .backup_shared æ–‡ä»¶")
    
    # ========================================================================
    # å†…å­˜ä¼˜åŒ–åŠŸèƒ½
    # ========================================================================
    
    def add_memory_optimization(self):
        """æ·»åŠ å†…å­˜ä¼˜åŒ–ä»£ç ï¼Œé˜²æ­¢æ‰¹é‡å¤„ç†æ—¶OOM"""
        print(f"\n{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}ğŸ§  æ·»åŠ å†…å­˜ä¼˜åŒ–{Colors.RESET}")
        print(f"{Colors.BOLD}{Colors.MAGENTA}{'='*70}{Colors.RESET}")
        
        print(f"\n{Colors.CYAN}å†…å­˜ä¼˜åŒ–å†…å®¹ï¼š{Colors.RESET}")
        print(f"  1. æ·»åŠ  gc.collect() åƒåœ¾å›æ”¶")
        print(f"  2. æ·»åŠ  torch.cuda.empty_cache() GPUç¼“å­˜æ¸…ç†")
        print(f"  3. å¤„ç†å®Œæ¯ä¸ªæ–‡ä»¶åé‡Šæ”¾å†…å­˜")
        print(f"  4. åˆ é™¤ä¸å†ä½¿ç”¨çš„å¤§å‹å˜é‡")
        print(f"  5. æ‰¹é‡å¤„ç†æ”¹ä¸ºåˆ†æ‰¹å¤„ç†ï¼ˆå¯é€‰ï¼‰")
        
        if not self.check_environment():
            return False
        
        if not self.create_backup(include_configs=True):
            return False
        
        print(f"\n{Colors.CYAN}{'='*70}{Colors.RESET}")
        print(f"{Colors.CYAN}ğŸ”¨ å¼€å§‹æ·»åŠ å†…å­˜ä¼˜åŒ–{Colors.RESET}")
        print(f"{Colors.CYAN}{'='*70}{Colors.RESET}")
        
        scripts_to_optimize = [
            ('run_dpsk_ocr_pdf_batch.py', self._add_memory_opt_pdf_batch),
            ('run_dpsk_ocr_eval_batch.py', self._add_memory_opt_eval_batch),
            ('run_dpsk_ocr_pdf.py', self._add_memory_opt_pdf),
            ('run_dpsk_ocr_image.py', self._add_memory_opt_image),
        ]
        
        for script_name, optimize_func in scripts_to_optimize:
            script_path = self.vllm_path / script_name
            if script_path.exists():
                print(f"\n{Colors.BLUE}ğŸ“ ä¼˜åŒ–: {script_name}{Colors.RESET}")
                try:
                    fixes = optimize_func(script_path)
                    if fixes:
                        print(f"  {Colors.GREEN}âœ“{Colors.RESET} å·²æ·»åŠ  {len(fixes)} å¤„å†…å­˜ä¼˜åŒ–:")
                        for fix in fixes:
                            print(f"      â€¢ {fix}")
                    else:
                        print(f"  {Colors.YELLOW}âŠ˜{Colors.RESET} å·²åŒ…å«å†…å­˜ä¼˜åŒ–æˆ–æ— éœ€ä¿®æ”¹")
                except Exception as e:
                    print(f"  {Colors.RED}âœ—{Colors.RESET} ä¼˜åŒ–å¤±è´¥: {e}")
            else:
                print(f"\n{Colors.YELLOW}âŠ˜{Colors.RESET} è„šæœ¬ä¸å­˜åœ¨: {script_name}")
        
        print(f"\n{Colors.GREEN}âœ… å†…å­˜ä¼˜åŒ–æ·»åŠ å®Œæˆï¼{Colors.RESET}")
        return True
    
    def _add_memory_opt_pdf_batch(self, filepath):
        """ä¸º run_dpsk_ocr_pdf_batch.py æ·»åŠ å†…å­˜ä¼˜åŒ–ï¼ˆé‡ç‚¹ä¼˜åŒ–RAMï¼‰"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # 1. æ·»åŠ  gc å¯¼å…¥
        if 'import gc' not in content:
            content = content.replace(
                'import torch\n',
                'import torch\nimport gc\n'
            )
            fixes.append('æ·»åŠ  gc æ¨¡å—å¯¼å…¥')
        
        # 2. æ·»åŠ å†…å­˜æ¸…ç†å‡½æ•°
        memory_cleanup_func = '''
def cleanup_memory():
    """æ¸…ç†å†…å­˜å’ŒGPUç¼“å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

# åˆ›å»ºå…¨å±€å•ä¾‹å¤„ç†å™¨ï¼ˆé¿å…é‡å¤åˆ›å»ºå¯¼è‡´å†…å­˜æ³„æ¼ï¼‰
_global_processor = None
def get_processor():
    global _global_processor
    if _global_processor is None:
        _global_processor = DeepseekOCRProcessor()
    return _global_processor

'''
        if 'def cleanup_memory():' not in content:
            content = content.replace(
                'class Colors:',
                memory_cleanup_func + 'class Colors:'
            )
            fixes.append('æ·»åŠ  cleanup_memory() å’Œå…¨å±€å¤„ç†å™¨å•ä¾‹')
        
        # 3. ä¿®å¤å…³é”®é—®é¢˜ï¼šprocess_single_image ä¸­æ¯æ¬¡åˆ›å»ºæ–°çš„å¤„ç†å™¨å®ä¾‹
        old_process_image = '''def process_single_image(image):
    """
    é¢„å¤„ç†å•å¼ å›¾ç‰‡ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰
    
    Args:
        image (Image): PIL Image å¯¹è±¡
        
    Returns:
        dict: åŒ…å«æç¤ºè¯å’Œå›¾åƒç‰¹å¾çš„å­—å…¸
    """
    prompt_in = PROMPT
    cache_item = {
        "prompt": prompt_in,
        "multi_modal_data": {
            "image": DeepseekOCRProcessor().tokenize_with_images(
                images=[image], 
                bos=True, 
                eos=True, 
                cropping=CROP_MODE
            )
        },
    }
    return cache_item'''
        
        new_process_image = '''def process_single_image(image):
    """
    é¢„å¤„ç†å•å¼ å›¾ç‰‡ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼Œå†…å­˜ä¼˜åŒ–ï¼‰
    
    Args:
        image (Image): PIL Image å¯¹è±¡
        
    Returns:
        dict: åŒ…å«æç¤ºè¯å’Œå›¾åƒç‰¹å¾çš„å­—å…¸
    """
    prompt_in = PROMPT
    # ä½¿ç”¨å…¨å±€å•ä¾‹å¤„ç†å™¨ï¼Œé¿å…æ¯æ¬¡åˆ›å»ºæ–°å®ä¾‹å¯¼è‡´å†…å­˜æ³„æ¼
    processor = get_processor()
    cache_item = {
        "prompt": prompt_in,
        "multi_modal_data": {
            "image": processor.tokenize_with_images(
                images=[image], 
                bos=True, 
                eos=True, 
                cropping=CROP_MODE
            )
        },
    }
    return cache_item'''
        
        if old_process_image in content:
            content = content.replace(old_process_image, new_process_image)
            fixes.append('ä½¿ç”¨å…¨å±€å•ä¾‹å¤„ç†å™¨ï¼ˆå…³é”®å†…å­˜ä¼˜åŒ–ï¼‰')
        
        # 4. åœ¨ process_single_pdf å‡½æ•°ä¸­æ·»åŠ åˆ†æ‰¹å¤„ç†å’Œæ¸…ç†
        # è¿™æ˜¯æœ€å…³é”®çš„å†…å­˜ä¼˜åŒ–ï¼šå°†æ‰€æœ‰é¡µé¢åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹å¤„ç†å®Œåé‡Šæ”¾å†…å­˜
        
        # æ¨¡å¼1ï¼šåŸå§‹æœªä¿®æ”¹çš„æ ¼å¼
        old_batch_process_v1 = '''        # 2. å¤šçº¿ç¨‹é¢„å¤„ç†
        print(f"{Colors.BLUE}ğŸ”„ æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡...{Colors.RESET}")
        with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:  
            batch_inputs = list(tqdm(
                executor.map(process_single_image, images),
                total=len(images),
                desc=f"é¢„å¤„ç† {pdf_name}",
                colour='blue'
            ))
        
        # 3. æ‰¹é‡OCRæ¨ç†
        print(f"{Colors.BLUE}ğŸ¤– æ­£åœ¨æ‰§è¡ŒOCRè¯†åˆ«...{Colors.RESET}")
        outputs_list = llm.generate(
            batch_inputs,
            sampling_params=sampling_params
        )'''
        
        # æ¨¡å¼2ï¼šå·²ç»è¢«é™åˆ¶çº¿ç¨‹æ•°ä¿®æ”¹è¿‡çš„æ ¼å¼
        old_batch_process_v2 = '''        # 2. å¤šçº¿ç¨‹é¢„å¤„ç†
        print(f"{Colors.BLUE}ğŸ”„ æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡...{Colors.RESET}")
        # æ³¨æ„ï¼šNUM_WORKERS è¿‡é«˜ä¼šå¯¼è‡´å†…å­˜å ç”¨è¿‡å¤§ï¼Œå»ºè®®è®¾ç½®ä¸º 4-8
        with ThreadPoolExecutor(max_workers=min(NUM_WORKERS, 8)) as executor:  
            batch_inputs = list(tqdm(
                executor.map(process_single_image, images),
                total=len(images),
                desc=f"é¢„å¤„ç† {pdf_name}",
                colour='blue'
            ))
        
        # 3. æ‰¹é‡OCRæ¨ç†
        print(f"{Colors.BLUE}ğŸ¤– æ­£åœ¨æ‰§è¡ŒOCRè¯†åˆ«...{Colors.RESET}")
        outputs_list = llm.generate(
            batch_inputs,
            sampling_params=sampling_params
        )'''
        
        new_batch_process = '''        # 2. å¤šçº¿ç¨‹é¢„å¤„ç†ï¼ˆåˆ†æ‰¹å¤„ç†ä»¥èŠ‚çœå†…å­˜ï¼‰
        print(f"{Colors.BLUE}ğŸ”„ æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡...{Colors.RESET}")
        
        # åˆ†æ‰¹å¤„ç†é…ç½® - æ¯æ‰¹å¤„ç†çš„é¡µé¢æ•°é‡
        PAGE_BATCH_SIZE = 20  # å¯æ ¹æ®RAMå¤§å°è°ƒæ•´ï¼š16GB RAMå»ºè®®10ï¼Œ32GBå»ºè®®20ï¼Œ64GB+å»ºè®®30
        
        outputs_list = []
        total_batches = (len(images) + PAGE_BATCH_SIZE - 1) // PAGE_BATCH_SIZE
        
        for batch_idx in range(0, len(images), PAGE_BATCH_SIZE):
            batch_images = images[batch_idx:batch_idx + PAGE_BATCH_SIZE]
            current_batch = batch_idx // PAGE_BATCH_SIZE + 1
            print(f"  ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {current_batch}/{total_batches} ({len(batch_images)} é¡µ)...")
            
            # é¢„å¤„ç†å½“å‰æ‰¹æ¬¡
            # æ³¨æ„ï¼šNUM_WORKERS è¿‡é«˜ä¼šå¯¼è‡´å†…å­˜å ç”¨è¿‡å¤§ï¼Œå»ºè®®è®¾ç½®ä¸º 4-8
            with ThreadPoolExecutor(max_workers=min(NUM_WORKERS, 8)) as executor:
                batch_inputs = list(tqdm(
                    executor.map(process_single_image, batch_images),
                    total=len(batch_images),
                    desc=f"æ‰¹æ¬¡ {current_batch}",
                    colour='blue',
                    leave=False
                ))
            
            # OCRæ¨ç†å½“å‰æ‰¹æ¬¡
            batch_outputs = llm.generate(
                batch_inputs,
                sampling_params=sampling_params
            )
            outputs_list.extend(batch_outputs)
            
            # ç«‹å³é‡Šæ”¾å½“å‰æ‰¹æ¬¡çš„å†…å­˜
            del batch_images, batch_inputs, batch_outputs
            cleanup_memory()
            print(f"  âœ“ æ‰¹æ¬¡ {current_batch} å®Œæˆï¼Œå·²é‡Šæ”¾å†…å­˜")
        
        print(f"{Colors.GREEN}âœ“{Colors.RESET} OCRè¯†åˆ«å®Œæˆ")'''
        
        if 'PAGE_BATCH_SIZE' not in content:
            # å°è¯•åŒ¹é…æ¨¡å¼1ï¼ˆåŸå§‹æ ¼å¼ï¼‰
            if old_batch_process_v1 in content:
                content = content.replace(old_batch_process_v1, new_batch_process)
                fixes.append('æ·»åŠ åˆ†æ‰¹å¤„ç†é€»è¾‘ï¼ˆå…³é”®RAMä¼˜åŒ–ï¼‰')
            # å°è¯•åŒ¹é…æ¨¡å¼2ï¼ˆå·²é™åˆ¶çº¿ç¨‹æ•°æ ¼å¼ï¼‰
            elif old_batch_process_v2 in content:
                content = content.replace(old_batch_process_v2, new_batch_process)
                fixes.append('æ·»åŠ åˆ†æ‰¹å¤„ç†é€»è¾‘ï¼ˆå…³é”®RAMä¼˜åŒ–ï¼‰')
            else:
                # å¦‚æœä¸¤ç§æ¨¡å¼éƒ½ä¸åŒ¹é…ï¼Œè‡³å°‘é™åˆ¶çº¿ç¨‹æ•°
                old_executor = 'with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:'
                new_executor = '''# æ³¨æ„ï¼šNUM_WORKERS è¿‡é«˜ä¼šå¯¼è‡´å†…å­˜å ç”¨è¿‡å¤§ï¼Œå»ºè®®è®¾ç½®ä¸º 4-8
        with ThreadPoolExecutor(max_workers=min(NUM_WORKERS, 8)) as executor:'''
                
                if old_executor in content and '# æ³¨æ„ï¼šNUM_WORKERS è¿‡é«˜' not in content:
                    content = content.replace(old_executor, new_executor)
                    fixes.append('é™åˆ¶æœ€å¤§çº¿ç¨‹æ•°ä¸º8ï¼ˆé˜²æ­¢RAMæº¢å‡ºï¼‰')
        
        # 6. åœ¨å¤„ç†å®Œæˆåæ·»åŠ æ¸…ç†ï¼ˆåœ¨ return ä¹‹åè¿›è¡Œï¼Œé¿å…å½±å“ return è¯­å¥ä¸­çš„å˜é‡å¼•ç”¨ï¼‰
        # æ³¨æ„ï¼šä¸åœ¨ return ä¹‹å‰åˆ é™¤ imagesï¼Œå› ä¸º return è¯­å¥éœ€è¦ len(images)
        # å†…å­˜æ¸…ç†å°†åœ¨ä¸»å¾ªç¯ä¸­è¿›è¡Œ
        
        # 7. åœ¨ä¸»å¾ªç¯æ¯ä¸ªPDFåæ¸…ç†
        old_loop = 'result = process_single_pdf(pdf_file, OUTPUT_PATH)'
        new_loop = '''result = process_single_pdf(pdf_file, OUTPUT_PATH)
        
        # æ¯å¤„ç†å®Œä¸€ä¸ªPDFå°±å¼ºåˆ¶æ¸…ç†å†…å­˜
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()'''
        
        if old_loop in content and '# æ¯å¤„ç†å®Œä¸€ä¸ªPDFå°±å¼ºåˆ¶æ¸…ç†å†…å­˜' not in content:
            content = content.replace(old_loop, new_loop)
            fixes.append('åœ¨PDFé—´æ·»åŠ å¼ºåˆ¶å†…å­˜æ¸…ç†')
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def _add_memory_opt_eval_batch(self, filepath):
        """ä¸º run_dpsk_ocr_eval_batch.py æ·»åŠ å†…å­˜ä¼˜åŒ–ï¼ˆé‡ç‚¹ä¼˜åŒ–RAMï¼‰"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # 1. æ·»åŠ  gc å¯¼å…¥
        if 'import gc' not in content:
            content = content.replace(
                'import torch\n',
                'import torch\nimport gc\n'
            )
            fixes.append('æ·»åŠ  gc æ¨¡å—å¯¼å…¥')
        
        # 2. æ·»åŠ å†…å­˜æ¸…ç†å‡½æ•°å’Œå…¨å±€å¤„ç†å™¨å•ä¾‹
        memory_cleanup_func = '''
def cleanup_memory():
    """æ¸…ç†å†…å­˜å’ŒGPUç¼“å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

# åˆ›å»ºå…¨å±€å•ä¾‹å¤„ç†å™¨ï¼ˆé¿å…é‡å¤åˆ›å»ºå¯¼è‡´å†…å­˜æ³„æ¼ï¼‰
_global_processor = None
def get_processor():
    global _global_processor
    if _global_processor is None:
        _global_processor = DeepseekOCRProcessor()
    return _global_processor

'''
        if 'def cleanup_memory():' not in content:
            content = content.replace(
                'class Colors:',
                memory_cleanup_func + 'class Colors:'
            )
            fixes.append('æ·»åŠ  cleanup_memory() å’Œå…¨å±€å¤„ç†å™¨å•ä¾‹')
        
        # 3. ä¿®å¤ process_single_image ä¸­åˆ›å»ºæ–°å¤„ç†å™¨çš„é—®é¢˜
        old_process = 'DeepseekOCRProcessor().tokenize_with_images('
        new_process = 'get_processor().tokenize_with_images('
        
        if old_process in content and 'get_processor()' not in content:
            content = content.replace(old_process, new_process)
            fixes.append('ä½¿ç”¨å…¨å±€å•ä¾‹å¤„ç†å™¨ï¼ˆå…³é”®å†…å­˜ä¼˜åŒ–ï¼‰')
        
        # 4. å®Œå…¨é‡å†™æ‰¹é‡å¤„ç†é€»è¾‘ - åˆ†æ‰¹åŠ è½½å’Œå¤„ç†
        # åŒ¹é…åŸå§‹æ–‡ä»¶ä¸­çš„å®é™…ä»£ç æ¨¡å¼
        old_batch_section_v1 = '''    images = []

    for image_path in images_path:
        image = Image.open(image_path).convert('RGB')
        images.append(image)

    prompt = PROMPT

    # batch_inputs = []


    # for image in tqdm(images):

    #     prompt_in = prompt
    #     cache_list = [
    #         {
    #             "prompt": prompt_in,
    #             "multi_modal_data": {"image": Image.open(image).convert('RGB')},
    #         }
    #     ]
    #     batch_inputs.extend(cache_list)

    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:  
        batch_inputs = list(tqdm(
            executor.map(process_single_image, images),
            total=len(images),
            desc="Pre-processed images"
        ))


    

    outputs_list = llm.generate(
        batch_inputs,
        sampling_params=sampling_params
    )'''
        
        # åŒ¹é…ç®€åŒ–ç‰ˆæœ¬
        old_batch_section_v2 = '''    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:  
        batch_inputs = list(tqdm(
            executor.map(process_single_image, images),
            total=len(images),
            desc="Pre-processed images"
        ))


    

    outputs_list = llm.generate(
        batch_inputs,
        sampling_params=sampling_params
    )'''
        
        new_batch_section = '''    prompt = PROMPT
    
    # åˆ†æ‰¹å¤„ç†é…ç½® - æ ¹æ®RAMå¤§å°è°ƒæ•´
    BATCH_SIZE = 10  # æ¯æ‰¹å¤„ç†çš„å›¾ç‰‡æ•°é‡ï¼š16GB RAMå»ºè®®5ï¼Œ32GBå»ºè®®10ï¼Œ64GB+å»ºè®®20
    
    outputs_list = []
    total_batches = (len(images_path) + BATCH_SIZE - 1) // BATCH_SIZE
    
    print(f'{Colors.GREEN}å¼€å§‹åˆ†æ‰¹å¤„ç† ({total_batches} æ‰¹æ¬¡ï¼Œæ¯æ‰¹ {BATCH_SIZE} å¼ )...{Colors.RESET}')
    
    for batch_idx in range(0, len(images_path), BATCH_SIZE):
        batch_paths = images_path[batch_idx:batch_idx + BATCH_SIZE]
        current_batch = batch_idx // BATCH_SIZE + 1
        print(f'\\n  ğŸ“¦ æ‰¹æ¬¡ {current_batch}/{total_batches}')
        
        # åŠ è½½å½“å‰æ‰¹æ¬¡çš„å›¾ç‰‡
        batch_images = []
        for img_path in batch_paths:
            img = Image.open(img_path).convert('RGB')
            batch_images.append(img)
        
        # é¢„å¤„ç†å½“å‰æ‰¹æ¬¡ï¼ˆé™åˆ¶çº¿ç¨‹æ•°é˜²æ­¢å†…å­˜æº¢å‡ºï¼‰
        with ThreadPoolExecutor(max_workers=min(NUM_WORKERS, 4)) as executor:
            batch_inputs = list(tqdm(
                executor.map(process_single_image, batch_images),
                total=len(batch_images),
                desc=f"é¢„å¤„ç†æ‰¹æ¬¡ {current_batch}",
                leave=False
            ))
        
        # é‡Šæ”¾åŸå§‹å›¾ç‰‡
        del batch_images
        gc.collect()
        
        # OCRæ¨ç†å½“å‰æ‰¹æ¬¡
        batch_outputs = llm.generate(
            batch_inputs,
            sampling_params=sampling_params
        )
        outputs_list.extend(batch_outputs)
        
        # é‡Šæ”¾å½“å‰æ‰¹æ¬¡æ•°æ®
        del batch_inputs, batch_outputs
        cleanup_memory()
        print(f'  âœ“ æ‰¹æ¬¡ {current_batch} å®Œæˆ')'''
        
        if 'BATCH_SIZE' not in content:
            if old_batch_section_v1 in content:
                content = content.replace(old_batch_section_v1, new_batch_section)
                fixes.append('å®Œå…¨é‡å†™ä¸ºåˆ†æ‰¹åŠ è½½å¤„ç†ï¼ˆå…³é”®RAMä¼˜åŒ–ï¼‰')
            elif old_batch_section_v2 in content:
                content = content.replace(old_batch_section_v2, new_batch_section)
                fixes.append('å®Œå…¨é‡å†™ä¸ºåˆ†æ‰¹åŠ è½½å¤„ç†ï¼ˆå…³é”®RAMä¼˜åŒ–ï¼‰')
        
        # 5. æ·»åŠ æœ€ç»ˆæ¸…ç† - åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ æ¸…ç†ä»£ç 
        old_end = '''        mmd_path = output_path + image.split('/')[-1].replace('.jpg', '.md')

        with open(mmd_path, 'w', encoding='utf-8') as afile:
            afile.write(content)'''
        
        new_end = '''        mmd_path = output_path + image.split('/')[-1].replace('.jpg', '.md')

        with open(mmd_path, 'w', encoding='utf-8') as afile:
            afile.write(content)
    
    # æœ€ç»ˆå†…å­˜æ¸…ç†
    del outputs_list
    cleanup_memory()
    print(f'{Colors.GREEN}æ‰¹é‡å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(images_path)} å¼ å›¾ç‰‡{Colors.RESET}')'''
        
        if old_end in content and '# æœ€ç»ˆå†…å­˜æ¸…ç†' not in content:
            content = content.replace(old_end, new_end)
            fixes.append('æ·»åŠ æœ€ç»ˆå†…å­˜æ¸…ç†')
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def _add_memory_opt_pdf(self, filepath):
        """ä¸º run_dpsk_ocr_pdf.py æ·»åŠ å†…å­˜ä¼˜åŒ–ï¼ˆé‡ç‚¹ä¼˜åŒ–RAMï¼‰"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # 1. æ·»åŠ  gc å¯¼å…¥
        if 'import gc' not in content:
            content = content.replace(
                'import torch\n',
                'import torch\nimport gc\n'
            )
            fixes.append('æ·»åŠ  gc æ¨¡å—å¯¼å…¥')
        
        # 2. æ·»åŠ å†…å­˜æ¸…ç†å‡½æ•°å’Œå…¨å±€å¤„ç†å™¨
        memory_cleanup_func = '''
def cleanup_memory():
    """æ¸…ç†å†…å­˜å’ŒGPUç¼“å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

# åˆ›å»ºå…¨å±€å•ä¾‹å¤„ç†å™¨ï¼ˆé¿å…é‡å¤åˆ›å»ºå¯¼è‡´å†…å­˜æ³„æ¼ï¼‰
_global_processor = None
def get_processor():
    global _global_processor
    if _global_processor is None:
        _global_processor = DeepseekOCRProcessor()
    return _global_processor

'''
        if 'def cleanup_memory():' not in content:
            content = content.replace(
                'class Colors:',
                memory_cleanup_func + 'class Colors:'
            )
            fixes.append('æ·»åŠ  cleanup_memory() å’Œå…¨å±€å¤„ç†å™¨å•ä¾‹')
        
        # 3. ä¿®å¤ process_single_image ä¸­åˆ›å»ºæ–°å¤„ç†å™¨çš„é—®é¢˜
        old_process = 'DeepseekOCRProcessor().tokenize_with_images('
        new_process = 'get_processor().tokenize_with_images('
        
        if old_process in content:
            content = content.replace(old_process, new_process)
            fixes.append('ä½¿ç”¨å…¨å±€å•ä¾‹å¤„ç†å™¨ï¼ˆå…³é”®å†…å­˜ä¼˜åŒ–ï¼‰')
        
        # 4. é™åˆ¶çº¿ç¨‹æ•°
        old_executor = 'with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:'
        new_executor = '''# æ³¨æ„ï¼šNUM_WORKERS è¿‡é«˜ä¼šå¯¼è‡´å†…å­˜å ç”¨è¿‡å¤§ï¼Œå»ºè®®è®¾ç½®ä¸º 4-8
        with ThreadPoolExecutor(max_workers=min(NUM_WORKERS, 8)) as executor:'''
        
        if old_executor in content and '# æ³¨æ„ï¼šNUM_WORKERS è¿‡é«˜' not in content:
            content = content.replace(old_executor, new_executor)
            fixes.append('é™åˆ¶æœ€å¤§çº¿ç¨‹æ•°ä¸º8ï¼ˆé˜²æ­¢RAMæº¢å‡ºï¼‰')
        
        # 5. åœ¨å¤„ç†å®Œæˆåæ¸…ç†
        old_success = "print(f'{Colors.GREEN}âœ… å¤„ç†å®Œæˆï¼{Colors.RESET}')"
        new_success = '''# æœ€ç»ˆå†…å­˜æ¸…ç†
        try:
            del images, draw_images
        except:
            pass
        cleanup_memory()
        
        print(f'{Colors.GREEN}âœ… å¤„ç†å®Œæˆï¼{Colors.RESET}')'''
        
        if old_success in content and '# æœ€ç»ˆå†…å­˜æ¸…ç†' not in content:
            content = content.replace(old_success, new_success)
            fixes.append('æ·»åŠ æœ€ç»ˆå†…å­˜æ¸…ç†')
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def _add_memory_opt_image(self, filepath):
        """ä¸º run_dpsk_ocr_image.py æ·»åŠ å†…å­˜ä¼˜åŒ–ï¼ˆé‡ç‚¹ä¼˜åŒ–RAMï¼‰"""
        fixes = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # 1. æ·»åŠ  gc å¯¼å…¥
        if 'import gc' not in content:
            content = content.replace(
                'import torch\n',
                'import torch\nimport gc\n'
            )
            fixes.append('æ·»åŠ  gc æ¨¡å—å¯¼å…¥')
        
        # 2. æ·»åŠ å†…å­˜æ¸…ç†å‡½æ•°
        memory_cleanup_func = '''
def cleanup_memory():
    """æ¸…ç†å†…å­˜å’ŒGPUç¼“å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

'''
        if 'def cleanup_memory():' not in content:
            # æ‰¾åˆ°åˆé€‚çš„ä½ç½®æ·»åŠ 
            if 'class Colors:' in content:
                content = content.replace(
                    'class Colors:',
                    memory_cleanup_func + 'class Colors:'
                )
                fixes.append('æ·»åŠ  cleanup_memory() å‡½æ•°')
            elif 'def load_image' in content:
                content = content.replace(
                    'def load_image',
                    memory_cleanup_func + 'def load_image'
                )
                fixes.append('æ·»åŠ  cleanup_memory() å‡½æ•°')
        
        # 3. åœ¨å¤„ç†å®Œæˆåæ·»åŠ æ¸…ç†
        if "if __name__ ==" in content and 'cleanup_memory()' not in content:
            # æ‰¾åˆ° main å‡½æ•°çš„æœ«å°¾ï¼Œæ·»åŠ æ¸…ç†
            old_main = 'if __name__ == "__main__":'
            new_main = '''# å¤„ç†å®Œæˆåé‡Šæ”¾å†…å­˜
def cleanup_after_processing():
    cleanup_memory()
    print("å†…å­˜å·²æ¸…ç†")

if __name__ == "__main__":'''
            
            if old_main in content and 'cleanup_after_processing' not in content:
                content = content.replace(old_main, new_main)
                fixes.append('æ·»åŠ å¤„ç†åæ¸…ç†å‡½æ•°')
        
        if content != original_content:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return fixes
        return None
    
    def run(self):
        """
        è¿è¡Œä¿®å¤æµç¨‹ï¼ˆé»˜è®¤å®Œæ•´ä¿®å¤ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
        """
        return self.run_full_fix()


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    project_path = sys.argv[1] if len(sys.argv) > 1 else None
    
    # åˆ›å»ºä¿®å¤å™¨
    fixer = T4CompatibilityFixer(project_path)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šéäº¤äº’æ¨¡å¼
    if len(sys.argv) > 2 and sys.argv[2] == '--auto':
        # è‡ªåŠ¨æ¨¡å¼ï¼šå®Œæ•´ä¿®å¤
        success = fixer.run()
        sys.exit(0 if success else 1)
    else:
        # äº¤äº’æ¨¡å¼
        fixer.run_interactive()


if __name__ == '__main__':
    main()
